{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import utils_HDF5 as utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TriHiggs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_triHiggs_h5_info(file_path):\n",
    "    # 印出 triHiggs HDF5 資料中，各 Higgs 數目的事件數\n",
    "    print(file_path)\n",
    "    with h5py.File(file_path, 'r') as f:\n",
    "\n",
    "        h1b1 = f['TARGETS/h1/b1'][...]\n",
    "        h1b2 = f['TARGETS/h1/b2'][...]\n",
    "        h2b1 = f['TARGETS/h2/b1'][...]\n",
    "        h2b2 = f['TARGETS/h2/b2'][...]\n",
    "        h3b1 = f['TARGETS/h3/b1'][...]\n",
    "        h3b2 = f['TARGETS/h3/b2'][...]\n",
    "\n",
    "        quark_jet = np.array([h1b1, h1b2, h2b1, h2b2, h3b1, h3b2]).T\n",
    "\n",
    "        h1_mask = utils.get_particle_mask(quark_jet, (0, 1))\n",
    "        h2_mask = utils.get_particle_mask(quark_jet, (2, 3))\n",
    "        h3_mask = utils.get_particle_mask(quark_jet, (4, 5))\n",
    "        \n",
    "        n_tot = h1_mask.shape[0]\n",
    "        n_0h = ((~h1_mask) & (~h2_mask) & (~h3_mask)).sum()\n",
    "        # 任一個 Higgs 有對應的 jet\n",
    "        n_1h = ((h1_mask & (~h2_mask) & (~h3_mask)) | \n",
    "                ((~h1_mask) & h2_mask & (~h3_mask)) | \n",
    "                ((~h1_mask) & (~h2_mask) & h3_mask)).sum()\n",
    "        \n",
    "        # 任兩個 Higgs 有對應的 jet\n",
    "        n_2h = ((h1_mask & h2_mask & (~h3_mask)) | \n",
    "                ((~h1_mask) & h2_mask & h3_mask) | \n",
    "                (h1_mask & (~h2_mask) & h3_mask)).sum()\n",
    "        n_3h = (h1_mask & h2_mask & h3_mask).sum()\n",
    "\n",
    "    print(f'Dataset size: {n_tot}')\n",
    "    print(f'Number of 0 Higgs events: {n_0h}')\n",
    "    print(f'Number of 1 Higgs events: {n_1h}')\n",
    "    print(f'Number of 2 Higgs events: {n_2h}')\n",
    "    print(f'Number of 3 Higgs events: {n_3h}')\n",
    "    \n",
    "    print(f'\\\\item Total sample size: {n_tot:,}')\n",
    "    print(f'\\\\item 1h sample size: {n_1h:,}')\n",
    "    print(f'\\\\item 2h sample size: {n_2h:,}')\n",
    "    print(f'\\\\item 3h sample size: {n_3h:,}')\n",
    "    \n",
    "    result = {\n",
    "        'total': n_tot,\n",
    "        '0h': n_0h,\n",
    "        '1h': n_1h,\n",
    "        '2h': n_2h,\n",
    "        '3h': n_3h\n",
    "    }\n",
    "    return result\n",
    "\n",
    "def print_h5_sb_info(file):\n",
    "    # 印出訊號與背景的事件數\n",
    "    with h5py.File(file,'r') as f:\n",
    "        n_tot = f['CLASSIFICATIONS/EVENT/signal'][...].shape[0]\n",
    "        ns = (f['CLASSIFICATIONS/EVENT/signal'][...] == 1).sum()\n",
    "        nb = (f['CLASSIFICATIONS/EVENT/signal'][...] == 0).sum()\n",
    "\n",
    "    print(f'\\\\item Total sample size: {n_tot:,}')\n",
    "    print(f'\\\\item Signal sample size: {ns:,}')\n",
    "    print(f'\\\\item Background sample size: {nb:,}')\n",
    "    \n",
    "\n",
    "def select_3h_event(file, output_file):\n",
    "    # 選取 triHiggs HDF5 資料中，有 3 個 Higgs 的事件\n",
    "    # root, ext = os.path.splitext(file)\n",
    "    # new_file = root + '_3h' + ext\n",
    "\n",
    "    with h5py.File(file, 'r') as f:\n",
    "        h1b1 = f['TARGETS/h1/b1'][...]\n",
    "        h1b2 = f['TARGETS/h1/b2'][...]\n",
    "        h2b1 = f['TARGETS/h2/b1'][...]\n",
    "        h2b2 = f['TARGETS/h2/b2'][...]\n",
    "        h3b1 = f['TARGETS/h3/b1'][...]\n",
    "        h3b2 = f['TARGETS/h3/b2'][...]\n",
    "\n",
    "        quark_jet = np.array([h1b1, h1b2, h2b1, h2b2, h3b1, h3b2]).T\n",
    "\n",
    "        h1_mask = utils.get_particle_mask(quark_jet, (0, 1))\n",
    "        h2_mask = utils.get_particle_mask(quark_jet, (2, 3))\n",
    "        h3_mask = utils.get_particle_mask(quark_jet, (4, 5))\n",
    "        \n",
    "        mask = h1_mask & h2_mask & h3_mask\n",
    "        n_3h = mask.sum()\n",
    "\n",
    "        print(f'Number of 3 Higgs events: {n_3h}')\n",
    "\n",
    "        # copy 3h events to new file\n",
    "        shutil.copyfile(file, output_file)\n",
    "        with h5py.File(output_file, 'a') as f_new:\n",
    "            for key in utils.get_dataset_keys(f):\n",
    "                f_new[key].resize(n_3h, axis=0)\n",
    "                f_new[key][:] = f[key][:][mask]\n",
    "\n",
    "    return output_file\n",
    "\n",
    "def select_nb_event(file, output_file, nb=6):\n",
    "    # 選取 triHiggs HDF5 資料中，有 nb 個 b-jets 的事件\n",
    "    # root, ext = os.path.splitext(file)\n",
    "\n",
    "    with h5py.File(file, 'r') as f:\n",
    "        bTag = f['INPUTS/Source/btag'][...]\n",
    "        n_b_jet = np.sum(bTag, axis=1)\n",
    "\n",
    "        mask = n_b_jet >= nb\n",
    "        n_6b = mask.sum()\n",
    "\n",
    "        print(f'Number of {nb} b events: {n_6b}')\n",
    "\n",
    "        # copy 3h events to new file\n",
    "        shutil.copyfile(file, output_file)\n",
    "        with h5py.File(output_file, 'a') as f_new:\n",
    "            for key in utils.get_dataset_keys(f):\n",
    "                f_new[key].resize(n_6b, axis=0)\n",
    "                f_new[key][:] = f[key][:][mask]\n",
    "\n",
    "    return output_file\n",
    "\n",
    "def select_4pT40_event(file, output_file):\n",
    "    # 選取 triHiggs HDF5 資料中，有 nb 個 b-jets 的事件\n",
    "    # root, ext = os.path.splitext(file)\n",
    "\n",
    "    with h5py.File(file, 'r') as f:\n",
    "        pt = f['INPUTS/Source/pt'][...]\n",
    "        pt_mask = pt[:, 3] > 40\n",
    "\n",
    "        n_event = pt_mask.sum()\n",
    "        print(f'Number of 4 pT > 40 GeV events: {n_event}')\n",
    "\n",
    "        # copy 3h events to new file\n",
    "        shutil.copyfile(file, output_file)\n",
    "        with h5py.File(output_file, 'a') as f_new:\n",
    "            for key in utils.get_dataset_keys(f):\n",
    "                f_new[key].resize(n_event, axis=0)\n",
    "                f_new[key][:] = f[key][:][pt_mask]\n",
    "\n",
    "    return output_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./Sample/SPANet/bkg/pp6b-pT25_0b.h5\n",
      "Dataset size: 5570742\n",
      "CLASSIFICATIONS/EVENT/signal 0\n",
      "INPUTS/Source/MASK [ True  True  True  True  True  True False False False False False False\n",
      " False False False]\n",
      "INPUTS/Source/btag [False  True False False  True  True False False False False False False\n",
      " False False False]\n",
      "INPUTS/Source/eta [-1.5613574   1.7147591   0.50634855 -2.4052203  -2.3219755   1.6762717\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.        ]\n",
      "INPUTS/Source/mass [18.679089   8.476983   9.943685   6.022513   7.6641026  3.0452356\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.       ]\n",
      "INPUTS/Source/phi [ 0.15385643  2.5918746   3.0130267  -1.8666257  -0.7792846   2.0502343\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.        ]\n",
      "INPUTS/Source/pt [80.86402  63.279446 46.487667 33.09533  30.195988 25.177929  0.\n",
      "  0.        0.        0.        0.        0.        0.        0.\n",
      "  0.      ]\n",
      "TARGETS/h1/b1 -1\n",
      "TARGETS/h1/b2 -1\n",
      "TARGETS/h2/b1 -1\n",
      "TARGETS/h2/b2 -1\n",
      "TARGETS/h3/b1 -1\n",
      "TARGETS/h3/b2 -1\n",
      "Number of 4 b events: 2431255\n",
      "./Sample/SPANet/bkg/pp6b-pT25_4b.h5\n",
      "Dataset size: 2431255\n",
      "Number of 0 Higgs events: 2431255\n",
      "Number of 1 Higgs events: 0\n",
      "Number of 2 Higgs events: 0\n",
      "Number of 3 Higgs events: 0\n",
      "\\item Total sample size: 2,431,255\n",
      "\\item 1h sample size: 0\n",
      "\\item 2h sample size: 0\n",
      "\\item 3h sample size: 0\n",
      "Number of 4 pT > 40 GeV events: 2030855\n",
      "./Sample/SPANet/bkg/pp6b-4pT40_4b.h5\n",
      "Dataset size: 2030855\n",
      "Number of 0 Higgs events: 2030855\n",
      "Number of 1 Higgs events: 0\n",
      "Number of 2 Higgs events: 0\n",
      "Number of 3 Higgs events: 0\n",
      "\\item Total sample size: 2,030,855\n",
      "\\item 1h sample size: 0\n",
      "\\item 2h sample size: 0\n",
      "\\item 3h sample size: 0\n",
      "Number of 6 b events: 139246\n",
      "./Sample/SPANet/bkg/pp6b-4pT40_6b.h5\n",
      "Dataset size: 139246\n",
      "Number of 0 Higgs events: 139246\n",
      "Number of 1 Higgs events: 0\n",
      "Number of 2 Higgs events: 0\n",
      "Number of 3 Higgs events: 0\n",
      "\\item Total sample size: 139,246\n",
      "\\item 1h sample size: 0\n",
      "\\item 2h sample size: 0\n",
      "\\item 3h sample size: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'total': 139246, '0h': 139246, '1h': 0, '2h': 0, '3h': 0}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = './Sample/SPANet/bkg/pp6b-pT25_0b.h5'\n",
    "utils.print_h5_info(file_path, 600)\n",
    "\n",
    "output_file = './Sample/SPANet/bkg/pp6b-pT25_4b.h5'\n",
    "four_b_file = select_nb_event(file_path, output_file, nb=4)\n",
    "print_triHiggs_h5_info(four_b_file)\n",
    "\n",
    "output_file = './Sample/SPANet/bkg/pp6b-4pT40_4b.h5'\n",
    "four_pT40_file = select_4pT40_event(four_b_file, output_file)\n",
    "print_triHiggs_h5_info(four_pT40_file)\n",
    "\n",
    "output_file = './Sample/SPANet/bkg/pp6b-4pT40_6b.h5'\n",
    "six_b_file = select_nb_event(four_pT40_file, output_file, nb=6)\n",
    "print_triHiggs_h5_info(six_b_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./Sample/SPANet/sig/gghhh_4b.h5\n",
      "Dataset size: 3653696\n",
      "CLASSIFICATIONS/EVENT/signal 1\n",
      "INPUTS/Source/MASK [ True  True  True  True  True  True False False False False False False\n",
      " False False False]\n",
      "INPUTS/Source/btag [ True False  True  True  True  True False False False False False False\n",
      " False False False]\n",
      "INPUTS/Source/eta [0.97436297 0.7894716  2.3529906  1.225184   0.7835297  0.6211857\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.        ]\n",
      "INPUTS/Source/mass [17.857948  10.667569   8.483025  11.8251505  5.751204   3.7765465\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.       ]\n",
      "INPUTS/Source/phi [-0.39327845  1.9963444  -0.4675336   2.6990483  -1.6782572   2.7238095\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.        ]\n",
      "INPUTS/Source/pt [103.46912   56.578156  51.16346   42.79874   37.01474   25.889942\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.      ]\n",
      "TARGETS/h1/b1 3\n",
      "TARGETS/h1/b2 0\n",
      "TARGETS/h2/b1 4\n",
      "TARGETS/h2/b2 1\n",
      "TARGETS/h3/b1 5\n",
      "TARGETS/h3/b2 2\n",
      "Number of 4 b events: 3653696\n",
      "./Sample/SPANet/sig/gghhh-4b.h5\n",
      "Dataset size: 3653696\n",
      "Number of 0 Higgs events: 223197\n",
      "Number of 1 Higgs events: 998906\n",
      "Number of 2 Higgs events: 1290603\n",
      "Number of 3 Higgs events: 1140990\n",
      "\\item Total sample size: 3,653,696\n",
      "\\item 1h sample size: 998,906\n",
      "\\item 2h sample size: 1,290,603\n",
      "\\item 3h sample size: 1,140,990\n",
      "Number of 4 pT > 40 GeV events: 3653696\n",
      "./Sample/SPANet/sig/gghhh-4pT40_4b.h5\n",
      "Dataset size: 3653696\n",
      "Number of 0 Higgs events: 223197\n",
      "Number of 1 Higgs events: 998906\n",
      "Number of 2 Higgs events: 1290603\n",
      "Number of 3 Higgs events: 1140990\n",
      "\\item Total sample size: 3,653,696\n",
      "\\item 1h sample size: 998,906\n",
      "\\item 2h sample size: 1,290,603\n",
      "\\item 3h sample size: 1,140,990\n",
      "Number of 6 b events: 451431\n",
      "./Sample/SPANet/sig/gghhh-4pT40_6b.h5\n",
      "Dataset size: 451431\n",
      "Number of 0 Higgs events: 5085\n",
      "Number of 1 Higgs events: 44775\n",
      "Number of 2 Higgs events: 92249\n",
      "Number of 3 Higgs events: 309322\n",
      "\\item Total sample size: 451,431\n",
      "\\item 1h sample size: 44,775\n",
      "\\item 2h sample size: 92,249\n",
      "\\item 3h sample size: 309,322\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'total': 451431, '0h': 5085, '1h': 44775, '2h': 92249, '3h': 309322}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = './Sample/SPANet/sig/gghhh-4pT40_4b.h5'\n",
    "\n",
    "output_file = './Sample/SPANet/sig/gghhh-4pT40_6b.h5'\n",
    "six_b_file = select_nb_event(file_path, output_file, nb=6)\n",
    "print_triHiggs_h5_info(six_b_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../SPANet2/data/triHiggs/triHiggs-4pT40_4b-train.h5\n",
      "Dataset size: 1800000\n",
      "Number of 0 Higgs events: 954693\n",
      "Number of 1 Higgs events: 246462\n",
      "Number of 2 Higgs events: 318057\n",
      "Number of 3 Higgs events: 280788\n",
      "\\item Total sample size: 1,800,000\n",
      "\\item 1h sample size: 246,462\n",
      "\\item 2h sample size: 318,057\n",
      "\\item 3h sample size: 280,788\n",
      "../SPANet2/data/triHiggs/triHiggs-4pT40_4b-test.h5\n",
      "Dataset size: 200000\n",
      "Number of 0 Higgs events: 106208\n",
      "Number of 1 Higgs events: 27243\n",
      "Number of 2 Higgs events: 35050\n",
      "Number of 3 Higgs events: 31499\n",
      "\\item Total sample size: 200,000\n",
      "\\item 1h sample size: 27,243\n",
      "\\item 2h sample size: 35,050\n",
      "\\item 3h sample size: 31,499\n",
      "\\item Total sample size: 1,800,000\n",
      "\\item Signal sample size: 900,000\n",
      "\\item Background sample size: 900,000\n",
      "\\item Total sample size: 200,000\n",
      "\\item Signal sample size: 100,000\n",
      "\\item Background sample size: 100,000\n"
     ]
    }
   ],
   "source": [
    "print_triHiggs_h5_info('../SPANet2/data/triHiggs/triHiggs-4pT40_4b-train.h5')\n",
    "print_triHiggs_h5_info('../SPANet2/data/triHiggs/triHiggs-4pT40_4b-test.h5')\n",
    "\n",
    "print_h5_sb_info('../SPANet2/data/triHiggs/triHiggs-4pT40_4b-train.h5')\n",
    "print_h5_sb_info('../SPANet2/data/triHiggs/triHiggs-4pT40_4b-test.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./Sample/SPANet/sig/gghhh-4pT40_6b-chi2_pairing.h5\n",
      "Dataset size: 50000\n",
      "CLASSIFICATIONS/EVENT/signal 1\n",
      "INPUTS/Source/MASK [ True  True  True  True  True  True False False False False False False\n",
      " False False False]\n",
      "INPUTS/Source/btag [ True  True  True  True  True  True False False False False False False\n",
      " False False False]\n",
      "INPUTS/Source/eta [ 0.25449502  0.5299419   1.0338726   0.55007374  0.08505747 -0.89098066\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.        ]\n",
      "INPUTS/Source/mass [ 6.8960032  9.977689  10.36412    4.2368584  9.395057   4.1449203\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.       ]\n",
      "INPUTS/Source/phi [ 2.160251   -1.5944599  -2.633631    0.70495915  0.50255275 -1.313326\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.        ]\n",
      "INPUTS/Source/pt [70.745316 60.724663 59.855797 55.8132   45.42086  39.351856  0.\n",
      "  0.        0.        0.        0.        0.        0.        0.\n",
      "  0.      ]\n",
      "TARGETS/h1/b1 3\n",
      "TARGETS/h1/b2 5\n",
      "TARGETS/h2/b1 0\n",
      "TARGETS/h2/b2 1\n",
      "TARGETS/h3/b1 2\n",
      "TARGETS/h3/b2 4\n"
     ]
    }
   ],
   "source": [
    "utils.print_h5_info('./Sample/SPANet/sig/gghhh-4pT40_6b-chi2_pairing.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Sample/SPANet/gghhh_0b_02.h5' and ('Sample/SPANet/gghhh_0b_03.h5', 'Sample/SPANet/gghhh_0b_04.h5', 'Sample/SPANet/gghhh_0b_05.h5', 'Sample/SPANet/gghhh_0b_06.h5', 'Sample/SPANet/gghhh_0b_07.h5', 'Sample/SPANet/gghhh_0b_08.h5', 'Sample/SPANet/gghhh_0b_323.h5', 'Sample/SPANet/gghhh_0b_423.h5', 'Sample/SPANet/gghhh_0b_523.h5', 'Sample/SPANet/gghhh_0b_614.h5', 'Sample/SPANet/gghhh_0b_714.h5') are same structure, can be merged.\n",
      "Sample/SPANet/gghhh_0b_02_merged.h5 not exist. Copy Sample/SPANet/gghhh_0b_02.h5 to Sample/SPANet/gghhh_0b_02_merged.h5\n",
      "Size of Sample/SPANet/gghhh_0b_02.h5: 304372\n",
      "Size of Sample/SPANet/gghhh_0b_03.h5: 303994\n",
      "Size of Sample/SPANet/gghhh_0b_02_merged.h5: 608366\n",
      "Size of Sample/SPANet/gghhh_0b_04.h5: 303915\n",
      "Size of Sample/SPANet/gghhh_0b_02_merged.h5: 912281\n",
      "Size of Sample/SPANet/gghhh_0b_05.h5: 304049\n",
      "Size of Sample/SPANet/gghhh_0b_02_merged.h5: 1216330\n",
      "Size of Sample/SPANet/gghhh_0b_06.h5: 304151\n",
      "Size of Sample/SPANet/gghhh_0b_02_merged.h5: 1520481\n",
      "Size of Sample/SPANet/gghhh_0b_07.h5: 304332\n",
      "Size of Sample/SPANet/gghhh_0b_02_merged.h5: 1824813\n",
      "Size of Sample/SPANet/gghhh_0b_08.h5: 305061\n",
      "Size of Sample/SPANet/gghhh_0b_02_merged.h5: 2129874\n",
      "Size of Sample/SPANet/gghhh_0b_323.h5: 304491\n",
      "Size of Sample/SPANet/gghhh_0b_02_merged.h5: 2434365\n",
      "Size of Sample/SPANet/gghhh_0b_423.h5: 305197\n",
      "Size of Sample/SPANet/gghhh_0b_02_merged.h5: 2739562\n",
      "Size of Sample/SPANet/gghhh_0b_523.h5: 304733\n",
      "Size of Sample/SPANet/gghhh_0b_02_merged.h5: 3044295\n",
      "Size of Sample/SPANet/gghhh_0b_614.h5: 304689\n",
      "Size of Sample/SPANet/gghhh_0b_02_merged.h5: 3348984\n",
      "Size of Sample/SPANet/gghhh_0b_714.h5: 304712\n",
      "Size of Sample/SPANet/gghhh_0b_02_merged.h5: 3653696\n"
     ]
    }
   ],
   "source": [
    "files = [f'Sample/SPANet/gghhh_0b_{i:02}.h5' for i in range(2, 9)] + [f'Sample/SPANet/gghhh_0b_{rnd}.h5' for rnd in [323, 423, 523, 614, 714]]\n",
    "\n",
    "merged_h5 = utils.merge_h5_file(*files)\n",
    "\n",
    "new_file = 'Sample/SPANet/gghhh_4b.h5'\n",
    "\n",
    "os.rename(merged_h5, new_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Sample/SPANet/gghhh_6b_02.h5' and ('Sample/SPANet/gghhh_6b_03.h5', 'Sample/SPANet/gghhh_6b_04.h5', 'Sample/SPANet/gghhh_6b_05.h5', 'Sample/SPANet/gghhh_6b_06.h5', 'Sample/SPANet/gghhh_6b_07.h5', 'Sample/SPANet/gghhh_6b_08.h5', 'Sample/SPANet/gghhh_6b_323.h5', 'Sample/SPANet/gghhh_6b_423.h5', 'Sample/SPANet/gghhh_6b_523.h5', 'Sample/SPANet/gghhh_6b_614.h5', 'Sample/SPANet/gghhh_6b_714.h5') are same structure, can be merged.\n",
      "Sample/SPANet/gghhh_6b_02_merged.h5 not exist. Copy Sample/SPANet/gghhh_6b_02.h5 to Sample/SPANet/gghhh_6b_02_merged.h5\n",
      "Size of Sample/SPANet/gghhh_6b_02.h5: 40565\n",
      "Size of Sample/SPANet/gghhh_6b_03.h5: 40866\n",
      "Size of Sample/SPANet/gghhh_6b_02_merged.h5: 81431\n",
      "Size of Sample/SPANet/gghhh_6b_04.h5: 40383\n",
      "Size of Sample/SPANet/gghhh_6b_02_merged.h5: 121814\n",
      "Size of Sample/SPANet/gghhh_6b_05.h5: 40879\n",
      "Size of Sample/SPANet/gghhh_6b_02_merged.h5: 162693\n",
      "Size of Sample/SPANet/gghhh_6b_06.h5: 40538\n",
      "Size of Sample/SPANet/gghhh_6b_02_merged.h5: 203231\n",
      "Size of Sample/SPANet/gghhh_6b_07.h5: 40489\n",
      "Size of Sample/SPANet/gghhh_6b_02_merged.h5: 243720\n",
      "Size of Sample/SPANet/gghhh_6b_08.h5: 40675\n",
      "Size of Sample/SPANet/gghhh_6b_02_merged.h5: 284395\n",
      "Size of Sample/SPANet/gghhh_6b_323.h5: 40256\n",
      "Size of Sample/SPANet/gghhh_6b_02_merged.h5: 324651\n",
      "Size of Sample/SPANet/gghhh_6b_423.h5: 40432\n",
      "Size of Sample/SPANet/gghhh_6b_02_merged.h5: 365083\n",
      "Size of Sample/SPANet/gghhh_6b_523.h5: 40623\n",
      "Size of Sample/SPANet/gghhh_6b_02_merged.h5: 405706\n",
      "Size of Sample/SPANet/gghhh_6b_614.h5: 40203\n",
      "Size of Sample/SPANet/gghhh_6b_02_merged.h5: 445909\n",
      "Size of Sample/SPANet/gghhh_6b_714.h5: 40785\n",
      "Size of Sample/SPANet/gghhh_6b_02_merged.h5: 486694\n"
     ]
    }
   ],
   "source": [
    "files = [f'Sample/SPANet/gghhh_6b_{i:02}.h5' for i in range(2, 9)] + [f'Sample/SPANet/gghhh_6b_{rnd}.h5' for rnd in [323, 423, 523, 614, 714]]\n",
    "\n",
    "merged_h5 = utils.merge_h5_file(*files)\n",
    "\n",
    "new_file = 'Sample/SPANet/gghhh_6b.h5'\n",
    "\n",
    "os.rename(merged_h5, new_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make training and testing dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of ./Sample/SPANet/bkg/pp6b-4pT40_4b.h5: 2030855\n",
      "Size of ./Sample/SPANet/bkg/pp6b-4pT40_4b_split1.h5: 1000000\n",
      "Size of ./Sample/SPANet/bkg/pp6b-4pT40_4b_split2.h5: 1030855\n"
     ]
    }
   ],
   "source": [
    "file_path = './Sample/SPANet/bkg/pp6b-4pT40_4b.h5'\n",
    "size = 1000000\n",
    "utils.split_h5_size(file_path, size)\n",
    "\n",
    "root, ext = os.path.splitext(file_path)\n",
    "split_file1 = root + '_split1' + ext\n",
    "split_file2 = root + '_split2' + ext\n",
    "\n",
    "os.rename(split_file1, './Sample/SPANet/bkg/pp6b-4pT40_4b-1.h5')\n",
    "os.rename(split_file2, './Sample/SPANet/bkg/pp6b-4pT40_4b-2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of ./Sample/SPANet/bkg/pp6b-4pT40_4b-1.h5: 1000000\n",
      "Size of ./Sample/SPANet/bkg/pp6b-4pT40_4b-1_split1.h5: 900000\n",
      "Size of ./Sample/SPANet/bkg/pp6b-4pT40_4b-1_split2.h5: 100000\n"
     ]
    }
   ],
   "source": [
    "file_path = './Sample/SPANet/bkg/pp6b-4pT40_4b-1.h5'\n",
    "size = 900000\n",
    "utils.split_h5_size(file_path, size)\n",
    "\n",
    "root, ext = os.path.splitext(file_path)\n",
    "split_file1 = root + '_split1' + ext\n",
    "split_file2 = root + '_split2' + ext\n",
    "\n",
    "os.rename(split_file1, './Sample/SPANet/bkg/pp6b-4pT40_4b-train.h5')\n",
    "os.rename(split_file2, './Sample/SPANet/bkg/pp6b-4pT40_4b-test.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of 6 b events: 70848\n",
      "./Sample/SPANet/bkg/pp6b-4pT40_6b.h5\n",
      "Dataset size: 70848\n",
      "Number of 0 Higgs events: 70848\n",
      "Number of 1 Higgs events: 0\n",
      "Number of 2 Higgs events: 0\n",
      "Number of 3 Higgs events: 0\n",
      "\\item Total sample size: 70,848\n",
      "\\item 1h sample size: 0\n",
      "\\item 2h sample size: 0\n",
      "\\item 3h sample size: 0\n",
      "Size of ./Sample/SPANet/bkg/pp6b-4pT40_6b.h5: 70848\n",
      "Size of ./Sample/SPANet/bkg/pp6b-4pT40_6b_split1.h5: 50000\n",
      "Size of ./Sample/SPANet/bkg/pp6b-4pT40_6b_split2.h5: 20848\n"
     ]
    }
   ],
   "source": [
    "output_file = './Sample/SPANet/bkg/pp6b-4pT40_6b.h5'\n",
    "six_b_file = select_nb_event('./Sample/SPANet/bkg/pp6b-4pT40_4b-2.h5', output_file, nb=6)\n",
    "print_triHiggs_h5_info(six_b_file)\n",
    "\n",
    "size = 50000\n",
    "utils.split_h5_size(six_b_file, size)\n",
    "\n",
    "root, ext = os.path.splitext(six_b_file)\n",
    "split_file1 = root + '_split1' + ext\n",
    "split_file2 = root + '_split2' + ext\n",
    "\n",
    "os.rename(split_file1, './Sample/SPANet/bkg/pp6b-4pT40_6b-1.h5')\n",
    "os.rename(split_file2, './Sample/SPANet/bkg/pp6b-4pT40_6b-2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of ./Sample/SPANet/sig/gghhh-4pT40_4b.h5: 3653696\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of ./Sample/SPANet/sig/gghhh-4pT40_4b_split1.h5: 1000000\n",
      "Size of ./Sample/SPANet/sig/gghhh-4pT40_4b_split2.h5: 2653696\n"
     ]
    }
   ],
   "source": [
    "file_path = './Sample/SPANet/sig/gghhh-4pT40_4b.h5'\n",
    "size = 1000000\n",
    "utils.split_h5_size(file_path, size)\n",
    "\n",
    "root, ext = os.path.splitext(file_path)\n",
    "split_file1 = root + '_split1' + ext\n",
    "split_file2 = root + '_split2' + ext\n",
    "\n",
    "os.rename(split_file1, './Sample/SPANet/sig/gghhh-4pT40_4b-1.h5')\n",
    "os.rename(split_file2, './Sample/SPANet/sig/gghhh-4pT40_4b-2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of ./Sample/SPANet/sig/gghhh-4pT40_4b-1.h5: 1000000\n",
      "Size of ./Sample/SPANet/sig/gghhh-4pT40_4b-1_split1.h5: 900000\n",
      "Size of ./Sample/SPANet/sig/gghhh-4pT40_4b-1_split2.h5: 100000\n"
     ]
    }
   ],
   "source": [
    "file_path = './Sample/SPANet/sig/gghhh-4pT40_4b-1.h5'\n",
    "size = 900000\n",
    "utils.split_h5_size(file_path, size)\n",
    "\n",
    "root, ext = os.path.splitext(file_path)\n",
    "split_file1 = root + '_split1' + ext\n",
    "split_file2 = root + '_split2' + ext\n",
    "\n",
    "os.rename(split_file1, './Sample/SPANet/sig/gghhh-4pT40_4b-train.h5')\n",
    "os.rename(split_file2, './Sample/SPANet/sig/gghhh-4pT40_4b-test.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of 6 b events: 327681\n",
      "./Sample/SPANet/sig/gghhh-4pT40_6b.h5\n",
      "Dataset size: 327681\n",
      "Number of 0 Higgs events: 3724\n",
      "Number of 1 Higgs events: 32449\n",
      "Number of 2 Higgs events: 67171\n",
      "Number of 3 Higgs events: 224337\n",
      "\\item Total sample size: 327,681\n",
      "\\item 1h sample size: 32,449\n",
      "\\item 2h sample size: 67,171\n",
      "\\item 3h sample size: 224,337\n",
      "Size of ./Sample/SPANet/sig/gghhh-4pT40_6b.h5: 327681\n",
      "Size of ./Sample/SPANet/sig/gghhh-4pT40_6b_split1.h5: 50000\n",
      "Size of ./Sample/SPANet/sig/gghhh-4pT40_6b_split2.h5: 277681\n"
     ]
    }
   ],
   "source": [
    "output_file = './Sample/SPANet/sig/gghhh-4pT40_6b.h5'\n",
    "six_b_file = select_nb_event('./Sample/SPANet/sig/gghhh-4pT40_4b-2.h5', output_file, nb=6)\n",
    "print_triHiggs_h5_info(six_b_file)\n",
    "\n",
    "size = 50000\n",
    "utils.split_h5_size(six_b_file, size)\n",
    "\n",
    "root, ext = os.path.splitext(six_b_file)\n",
    "split_file1 = root + '_split1' + ext\n",
    "split_file2 = root + '_split2' + ext\n",
    "\n",
    "os.rename(split_file1, './Sample/SPANet/sig/gghhh-4pT40_6b-1.h5')\n",
    "os.rename(split_file2, './Sample/SPANet/sig/gghhh-4pT40_6b-2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $4b$ dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'./Sample/SPANet/bkg/pp6b-4pT40_4b-train.h5' and ('./Sample/SPANet/sig/gghhh-4pT40_4b-train.h5',) are same structure, can be merged.\n",
      "./Sample/SPANet/bkg/pp6b-4pT40_4b-train_merged.h5 not exist. Copy ./Sample/SPANet/bkg/pp6b-4pT40_4b-train.h5 to ./Sample/SPANet/bkg/pp6b-4pT40_4b-train_merged.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of ./Sample/SPANet/bkg/pp6b-4pT40_4b-train.h5: 900000\n",
      "Size of ./Sample/SPANet/sig/gghhh-4pT40_4b-train.h5: 900000\n",
      "Size of ./Sample/SPANet/bkg/pp6b-4pT40_4b-train_merged.h5: 1800000\n"
     ]
    }
   ],
   "source": [
    "files = ['./Sample/SPANet/bkg/pp6b-4pT40_4b-train.h5', './Sample/SPANet/sig/gghhh-4pT40_4b-train.h5']\n",
    "merged_h5 = utils.merge_h5_file(*files)\n",
    "\n",
    "new_file = 'Sample/SPANet/triHiggs-4pT40_4b-train.h5'\n",
    "os.rename(merged_h5, new_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'./Sample/SPANet/bkg/pp6b-4pT40_4b-test.h5' and ('./Sample/SPANet/sig/gghhh-4pT40_4b-test.h5',) are same structure, can be merged.\n",
      "./Sample/SPANet/bkg/pp6b-4pT40_4b-test_merged.h5 not exist. Copy ./Sample/SPANet/bkg/pp6b-4pT40_4b-test.h5 to ./Sample/SPANet/bkg/pp6b-4pT40_4b-test_merged.h5\n",
      "Size of ./Sample/SPANet/bkg/pp6b-4pT40_4b-test.h5: 100000\n",
      "Size of ./Sample/SPANet/sig/gghhh-4pT40_4b-test.h5: 100000\n",
      "Size of ./Sample/SPANet/bkg/pp6b-4pT40_4b-test_merged.h5: 200000\n"
     ]
    }
   ],
   "source": [
    "files = ['./Sample/SPANet/bkg/pp6b-4pT40_4b-test.h5', './Sample/SPANet/sig/gghhh-4pT40_4b-test.h5']\n",
    "merged_h5 = utils.merge_h5_file(*files)\n",
    "\n",
    "new_file = 'Sample/SPANet/triHiggs-4pT40_4b-test.h5'\n",
    "os.rename(merged_h5, new_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 1800000\n",
      "Dataset size: 200000\n"
     ]
    }
   ],
   "source": [
    "utils.shuffle_h5('Sample/SPANet/triHiggs-4pT40_4b-train.h5')\n",
    "utils.shuffle_h5('Sample/SPANet/triHiggs-4pT40_4b-test.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_labels(file_path, label_path):\n",
    "    with h5py.File(label_path, 'r') as f:\n",
    "        label = f['CLASSIFICATIONS/EVENT/signal'][...]\n",
    "\n",
    "    with h5py.File(file_path, 'r+') as f:\n",
    "        if 'CLASSIFICATIONS/EVENT/signal' in f:\n",
    "            del f['CLASSIFICATIONS/EVENT/signal']\n",
    "        f.create_dataset('CLASSIFICATIONS/EVENT/signal', data=label, chunks=True, maxshape=(None,))\n",
    "\n",
    "file_path = 'Sample/SPANet/triHiggs-4pT40_4b-train-4b_SPANet_pairing.h5'\n",
    "label_path = 'Sample/SPANet/triHiggs-4pT40_4b-train.h5'\n",
    "replace_labels(file_path, label_path)\n",
    "\n",
    "file_path = 'Sample/SPANet/triHiggs-4pT40_4b-test-4b_SPANet_pairing.h5'\n",
    "label_path = 'Sample/SPANet/triHiggs-4pT40_4b-test.h5'\n",
    "replace_labels(file_path, label_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $6b$ dataset: 50k + 50K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'./Sample/SPANet/bkg/pp6b-4pT40_6b-1.h5' and ('./Sample/SPANet/sig/gghhh-4pT40_6b-1.h5',) are same structure, can be merged.\n",
      "./Sample/SPANet/bkg/pp6b-4pT40_6b-1_merged.h5 not exist. Copy ./Sample/SPANet/bkg/pp6b-4pT40_6b-1.h5 to ./Sample/SPANet/bkg/pp6b-4pT40_6b-1_merged.h5\n",
      "Size of ./Sample/SPANet/bkg/pp6b-4pT40_6b-1.h5: 50000\n",
      "Size of ./Sample/SPANet/sig/gghhh-4pT40_6b-1.h5: 50000\n",
      "Size of ./Sample/SPANet/bkg/pp6b-4pT40_6b-1_merged.h5: 100000\n"
     ]
    }
   ],
   "source": [
    "files = ['./Sample/SPANet/bkg/pp6b-4pT40_6b-1.h5', './Sample/SPANet/sig/gghhh-4pT40_6b-1.h5']\n",
    "merged_h5 = utils.merge_h5_file(*files)\n",
    "\n",
    "new_file = 'Sample/SPANet/triHiggs-4pT40_6b.h5'\n",
    "os.rename(merged_h5, new_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate 6b event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./Sample/SPANet/pp6b_0b.h5\n",
      "Dataset size: 1000000\n",
      "Number of 0 Higgs events: 1000000\n",
      "Number of 1 Higgs events: 0\n",
      "Number of 2 Higgs events: 0\n",
      "Number of 3 Higgs events: 0\n",
      "\\item Total sample size: 1,000,000\n",
      "\\item 1h sample size: 0\n",
      "\\item 2h sample size: 0\n",
      "\\item 3h sample size: 0\n",
      "Number of 6 b events: 28755\n",
      "./Sample/SPANet/pp6b_6b.h5\n",
      "Dataset size: 28755\n",
      "Number of 0 Higgs events: 28755\n",
      "Number of 1 Higgs events: 0\n",
      "Number of 2 Higgs events: 0\n",
      "Number of 3 Higgs events: 0\n",
      "\\item Total sample size: 28,755\n",
      "\\item 1h sample size: 0\n",
      "\\item 2h sample size: 0\n",
      "\\item 3h sample size: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'total': 28755, '0h': 28755, '1h': 0, '2h': 0, '3h': 0}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = './Sample/SPANet/pp6b_0b.h5'\n",
    "print_triHiggs_h5_info(file_path)\n",
    "\n",
    "output_file = './Sample/SPANet/pp6b_6b.h5'\n",
    "six_b_file = select_6b_event(file_path, output_file)\n",
    "print_triHiggs_h5_info(six_b_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'./Sample/SPANet/pp6b_0b.h5' and ('./Sample/SPANet/pp6b_0b_2.h5',) are same structure, can be merged.\n",
      "./Sample/SPANet/pp6b_0b_merged.h5 not exist. Copy ./Sample/SPANet/pp6b_0b.h5 to ./Sample/SPANet/pp6b_0b_merged.h5\n",
      "Size of ./Sample/SPANet/pp6b_0b.h5: 1000000\n",
      "Size of ./Sample/SPANet/pp6b_0b_2.h5: 808254\n",
      "Size of ./Sample/SPANet/pp6b_0b_merged.h5: 1808254\n",
      "./Sample/SPANet/pp6b_0b_merged.h5\n",
      "Dataset size: 1808254\n",
      "Number of 0 Higgs events: 1808254\n",
      "Number of 1 Higgs events: 0\n",
      "Number of 2 Higgs events: 0\n",
      "Number of 3 Higgs events: 0\n",
      "\\item Total sample size: 1,808,254\n",
      "\\item 1h sample size: 0\n",
      "\\item 2h sample size: 0\n",
      "\\item 3h sample size: 0\n",
      "Number of 4 b events: 790372\n",
      "./Sample/SPANet/pp6b_4b.h5\n",
      "Dataset size: 790372\n",
      "Number of 0 Higgs events: 790372\n",
      "Number of 1 Higgs events: 0\n",
      "Number of 2 Higgs events: 0\n",
      "Number of 3 Higgs events: 0\n",
      "\\item Total sample size: 790,372\n",
      "\\item 1h sample size: 0\n",
      "\\item 2h sample size: 0\n",
      "\\item 3h sample size: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'total': 790372, '0h': 790372, '1h': 0, '2h': 0, '3h': 0}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = ['./Sample/SPANet/pp6b_0b.h5', './Sample/SPANet/pp6b_0b_2.h5']\n",
    "file_path = utils.merge_h5_file(*files)\n",
    "print_triHiggs_h5_info(file_path)\n",
    "\n",
    "output_file = './Sample/SPANet/pp6b_4b.h5'\n",
    "nb_file = select_nb_event(file_path, output_file, nb=4)\n",
    "print_triHiggs_h5_info(nb_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../SPANet2/data/triHiggs/triHiggs_0b_3h_test.h5\n",
      "Dataset size: 200000\n",
      "Number of 0 Higgs events: 100000\n",
      "Number of 1 Higgs events: 0\n",
      "Number of 2 Higgs events: 0\n",
      "Number of 3 Higgs events: 100000\n",
      "\\item Total sample size: 200,000\n",
      "\\item 1h sample size: 0\n",
      "\\item 2h sample size: 0\n",
      "\\item 3h sample size: 100,000\n",
      "Number of 6 b events: 11521\n",
      "../SPANet2/data/triHiggs/triHiggs_6b_3h_test.h5\n",
      "Dataset size: 11521\n",
      "Number of 0 Higgs events: 2905\n",
      "Number of 1 Higgs events: 0\n",
      "Number of 2 Higgs events: 0\n",
      "Number of 3 Higgs events: 8616\n",
      "\\item Total sample size: 11,521\n",
      "\\item 1h sample size: 0\n",
      "\\item 2h sample size: 0\n",
      "\\item 3h sample size: 8,616\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'total': 11521, '0h': 2905, '1h': 0, '2h': 0, '3h': 8616}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = '../SPANet2/data/triHiggs/triHiggs_0b_3h_test.h5'\n",
    "print_triHiggs_h5_info(file_path)\n",
    "\n",
    "output_file = '../SPANet2/data/triHiggs/triHiggs_6b_3h_test.h5'\n",
    "six_b_file = select_6b_event(file_path, output_file)\n",
    "print_triHiggs_h5_info(six_b_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../SPANet2/data/triHiggs/triHiggs_0b_3h_test.h5\n",
      "Dataset size: 200000\n",
      "Number of 0 Higgs events: 100000\n",
      "Number of 1 Higgs events: 0\n",
      "Number of 2 Higgs events: 0\n",
      "Number of 3 Higgs events: 100000\n",
      "\\item Total sample size: 200,000\n",
      "\\item 1h sample size: 0\n",
      "\\item 2h sample size: 0\n",
      "\\item 3h sample size: 100,000\n",
      "Number of 6 b events: 11521\n",
      "../SPANet2/data/triHiggs/triHiggs_6b_3h_test.h5\n",
      "Dataset size: 11521\n",
      "Number of 0 Higgs events: 2905\n",
      "Number of 1 Higgs events: 0\n",
      "Number of 2 Higgs events: 0\n",
      "Number of 3 Higgs events: 8616\n",
      "\\item Total sample size: 11,521\n",
      "\\item 1h sample size: 0\n",
      "\\item 2h sample size: 0\n",
      "\\item 3h sample size: 8,616\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'total': 11521, '0h': 2905, '1h': 0, '2h': 0, '3h': 8616}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "file_path = '../SPANet2/data/triHiggs/triHiggs_0b_3h_test.h5'\n",
    "print_triHiggs_h5_info(file_path)\n",
    "\n",
    "output_file = '../SPANet2/data/triHiggs/triHiggs_6b_3h_test.h5'\n",
    "six_b_file = select_6b_event(file_path, output_file)\n",
    "print_triHiggs_h5_info(six_b_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare training and testing datasets with at least 4 jet $ > 40 \\text{ GeV}$ and 4 $b$-tagged jet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of Sample/SPANet/gghhh_4b.h5: 3653696\n",
      "Size of Sample/SPANet/gghhh_4b_split1.h5: 1000000\n",
      "Size of Sample/SPANet/gghhh_4b_split2.h5: 2653696\n",
      "Size of Sample/SPANet/gghhh_4b_split2.h5: 2653696\n",
      "Size of Sample/SPANet/gghhh_4b_split2_split1.h5: 500000\n",
      "Size of Sample/SPANet/gghhh_4b_split2_split2.h5: 2153696\n"
     ]
    }
   ],
   "source": [
    "file_path = 'Sample/SPANet/gghhh_4b.h5'\n",
    "size = 1000000\n",
    "utils.split_h5_size(file_path, size)\n",
    "\n",
    "root, ext = os.path.splitext(file_path)\n",
    "split_file1 = root + '_split1' + ext\n",
    "split_file2 = root + '_split2' + ext\n",
    "\n",
    "os.rename(split_file1, './Sample/SPANet/gghhh_4b_PT40.h5')\n",
    "\n",
    "size = 500000\n",
    "utils.split_h5_size(split_file2, size)\n",
    "\n",
    "root, ext = os.path.splitext(split_file2)\n",
    "split_file1 = root + '_split1' + ext\n",
    "split_file2 = root + '_split2' + ext\n",
    "\n",
    "os.rename(split_file1, './Sample/SPANet/gghhh_4b_PT40_DNN.h5')\n",
    "os.remove(split_file2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of ./Sample/SPANet/gghhh_4b_PT40.h5: 1000000\n",
      "Size of ./Sample/SPANet/gghhh_4b_PT40_split1.h5: 900000\n",
      "Size of ./Sample/SPANet/gghhh_4b_PT40_split2.h5: 100000\n"
     ]
    }
   ],
   "source": [
    "file_path = './Sample/SPANet/gghhh_4b_PT40.h5'\n",
    "r = 0.9\n",
    "utils.split_h5_file(file_path, r)\n",
    "\n",
    "root, ext = os.path.splitext(file_path)\n",
    "split_file1 = root + '_split1' + ext\n",
    "split_file2 = root + '_split2' + ext\n",
    "\n",
    "os.rename(split_file1, './Sample/SPANet/gghhh_4b_PT40_train.h5')\n",
    "os.rename(split_file2, './Sample/SPANet/gghhh_4b_PT40_test.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../SPANet2/data/triHiggs/gghhh_4b_PT40_train.h5\n",
      "Dataset size: 900000\n",
      "Number of 0 Higgs events: 54693\n",
      "Number of 1 Higgs events: 246462\n",
      "Number of 2 Higgs events: 318057\n",
      "Number of 3 Higgs events: 280788\n",
      "\\item Total sample size: 900,000\n",
      "\\item 1h sample size: 246,462\n",
      "\\item 2h sample size: 318,057\n",
      "\\item 3h sample size: 280,788\n",
      "Number of 3 Higgs events: 280788\n",
      "../SPANet2/data/triHiggs/gghhh_4b_PT40_3h_train.h5\n",
      "Dataset size: 280788\n",
      "Number of 0 Higgs events: 0\n",
      "Number of 1 Higgs events: 0\n",
      "Number of 2 Higgs events: 0\n",
      "Number of 3 Higgs events: 280788\n",
      "\\item Total sample size: 280,788\n",
      "\\item 1h sample size: 0\n",
      "\\item 2h sample size: 0\n",
      "\\item 3h sample size: 280,788\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'total': 280788, '0h': 0, '1h': 0, '2h': 0, '3h': 280788}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = '../SPANet2/data/triHiggs/gghhh_4b_PT40_train.h5'\n",
    "print_triHiggs_h5_info(file_path)\n",
    "\n",
    "output_file = '../SPANet2/data/triHiggs/gghhh_4b_PT40_3h_train.h5'\n",
    "triHiggs_file = select_3h_event(file_path, output_file)\n",
    "print_triHiggs_h5_info(triHiggs_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../SPANet2/data/triHiggs/gghhh_4b_PT40_test.h5\n",
      "Dataset size: 100000\n",
      "Number of 0 Higgs events: 6208\n",
      "Number of 1 Higgs events: 27243\n",
      "Number of 2 Higgs events: 35050\n",
      "Number of 3 Higgs events: 31499\n",
      "\\item Total sample size: 100,000\n",
      "\\item 1h sample size: 27,243\n",
      "\\item 2h sample size: 35,050\n",
      "\\item 3h sample size: 31,499\n",
      "Number of 3 Higgs events: 31499\n",
      "../SPANet2/data/triHiggs/gghhh_4b_PT40_3h_test.h5\n",
      "Dataset size: 31499\n",
      "Number of 0 Higgs events: 0\n",
      "Number of 1 Higgs events: 0\n",
      "Number of 2 Higgs events: 0\n",
      "Number of 3 Higgs events: 31499\n",
      "\\item Total sample size: 31,499\n",
      "\\item 1h sample size: 0\n",
      "\\item 2h sample size: 0\n",
      "\\item 3h sample size: 31,499\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'total': 31499, '0h': 0, '1h': 0, '2h': 0, '3h': 31499}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = '../SPANet2/data/triHiggs/gghhh_4b_PT40_test.h5'\n",
    "print_triHiggs_h5_info(file_path)\n",
    "\n",
    "output_file = '../SPANet2/data/triHiggs/gghhh_4b_PT40_3h_test.h5'\n",
    "triHiggs_file = select_3h_event(file_path, output_file)\n",
    "print_triHiggs_h5_info(triHiggs_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../SPANet2/data/triHiggs/triHiggs_4b_PT40_3h_train.h5\n",
      "Dataset size: 280788\n",
      "Number of 0 Higgs events: 0\n",
      "Number of 1 Higgs events: 0\n",
      "Number of 2 Higgs events: 0\n",
      "Number of 3 Higgs events: 280788\n",
      "\\item Total sample size: 280,788\n",
      "\\item 1h sample size: 0\n",
      "\\item 2h sample size: 0\n",
      "\\item 3h sample size: 280,788\n",
      "Number of 6 b events: 76506\n",
      "../SPANet2/data/triHiggs/triHiggs_6b_PT40_3h_train.h5\n",
      "Dataset size: 76506\n",
      "Number of 0 Higgs events: 0\n",
      "Number of 1 Higgs events: 0\n",
      "Number of 2 Higgs events: 0\n",
      "Number of 3 Higgs events: 76506\n",
      "\\item Total sample size: 76,506\n",
      "\\item 1h sample size: 0\n",
      "\\item 2h sample size: 0\n",
      "\\item 3h sample size: 76,506\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'total': 76506, '0h': 0, '1h': 0, '2h': 0, '3h': 76506}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = '../SPANet2/data/triHiggs/triHiggs_4b_PT40_3h_train.h5'\n",
    "print_triHiggs_h5_info(file_path)\n",
    "\n",
    "output_file = '../SPANet2/data/triHiggs/triHiggs_6b_PT40_3h_train.h5'\n",
    "six_b_file = select_6b_event(file_path, output_file)\n",
    "print_triHiggs_h5_info(six_b_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./Sample/SPANet/gghhh_4b_PT40_new.h5\n",
      "Dataset size: 32337\n",
      "Number of 0 Higgs events: 2111\n",
      "Number of 1 Higgs events: 8941\n",
      "Number of 2 Higgs events: 11341\n",
      "Number of 3 Higgs events: 9944\n",
      "\\item Total sample size: 32,337\n",
      "\\item 1h sample size: 8,941\n",
      "\\item 2h sample size: 11,341\n",
      "\\item 3h sample size: 9,944\n",
      "Number of 3 Higgs events: 9944\n",
      "./Sample/SPANet/gghhh_4b_PT40_3h_new.h5\n",
      "Dataset size: 9944\n",
      "Number of 0 Higgs events: 0\n",
      "Number of 1 Higgs events: 0\n",
      "Number of 2 Higgs events: 0\n",
      "Number of 3 Higgs events: 9944\n",
      "\\item Total sample size: 9,944\n",
      "\\item 1h sample size: 0\n",
      "\\item 2h sample size: 0\n",
      "\\item 3h sample size: 9,944\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'total': 9944, '0h': 0, '1h': 0, '2h': 0, '3h': 9944}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = './Sample/SPANet/gghhh_4b_PT40_new.h5'\n",
    "print_triHiggs_h5_info(file_path)\n",
    "\n",
    "output_file = './Sample/SPANet/gghhh_4b_PT40_3h_new.h5'\n",
    "triHiggs_file = select_3h_event(file_path, output_file)\n",
    "print_triHiggs_h5_info(triHiggs_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample/SPANet/gghhh_4b.h5\n",
      "Dataset size: 3653696\n",
      "Number of 0 Higgs events: 223197\n",
      "Number of 1 Higgs events: 998906\n",
      "Number of 2 Higgs events: 1290603\n",
      "Number of 3 Higgs events: 1140990\n",
      "\\item Total sample size: 3,653,696\n",
      "\\item 1h sample size: 998,906\n",
      "\\item 2h sample size: 1,290,603\n",
      "\\item 3h sample size: 1,140,990\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'total': 3653696, '0h': 223197, '1h': 998906, '2h': 1290603, '3h': 1140990}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = 'Sample/SPANet/gghhh_4b.h5'\n",
    "print_triHiggs_h5_info(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of Sample/SPANet/gghhh_4b.h5: 3653696\n",
      "Size of Sample/SPANet/gghhh_4b_split1.h5: 500000\n",
      "Size of Sample/SPANet/gghhh_4b_split2.h5: 3153696\n"
     ]
    }
   ],
   "source": [
    "file_path = 'Sample/SPANet/gghhh_4b.h5'\n",
    "size = 500000\n",
    "utils.split_h5_size(file_path, size)\n",
    "\n",
    "root, ext = os.path.splitext(file_path)\n",
    "split_file1 = root + '_split1' + ext\n",
    "split_file2 = root + '_split2' + ext\n",
    "\n",
    "os.rename(split_file1, './Sample/SPANet/gghhh_4b_PT40.h5')\n",
    "os.remove(split_file2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of Sample/SPANet/gghhh_4b_PT40.h5: 500000\n",
      "Size of Sample/SPANet/gghhh_4b_PT40_split1.h5: 450000\n",
      "Size of Sample/SPANet/gghhh_4b_PT40_split2.h5: 50000\n"
     ]
    }
   ],
   "source": [
    "file_path = 'Sample/SPANet/gghhh_4b_PT40.h5'\n",
    "r = 0.9\n",
    "utils.split_h5_file(file_path, r)\n",
    "\n",
    "root, ext = os.path.splitext(file_path)\n",
    "split_file1 = root + '_split1' + ext\n",
    "split_file2 = root + '_split2' + ext\n",
    "\n",
    "os.rename(split_file1, './Sample/SPANet/gghhh_4b_PT40_train.h5')\n",
    "os.rename(split_file2, './Sample/SPANet/gghhh_4b_PT40_test.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of ./Sample/SPANet/pp6b_4b.h5: 790372\n",
      "Size of ./Sample/SPANet/pp6b_4b_split1.h5: 500000\n",
      "Size of ./Sample/SPANet/pp6b_4b_split2.h5: 290372\n"
     ]
    }
   ],
   "source": [
    "file_path = './Sample/SPANet/pp6b_4b.h5'\n",
    "size = 500000\n",
    "utils.split_h5_size(file_path, size)\n",
    "\n",
    "root, ext = os.path.splitext(file_path)\n",
    "split_file1 = root + '_split1' + ext\n",
    "split_file2 = root + '_split2' + ext\n",
    "\n",
    "os.rename(split_file1, './Sample/SPANet/pp6b_4b_PT40.h5')\n",
    "os.remove(split_file2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of ./Sample/SPANet/pp6b_4b_PT40.h5: 500000\n",
      "Size of ./Sample/SPANet/pp6b_4b_PT40_split1.h5: 450000\n",
      "Size of ./Sample/SPANet/pp6b_4b_PT40_split2.h5: 50000\n"
     ]
    }
   ],
   "source": [
    "file_path = './Sample/SPANet/pp6b_4b_PT40.h5'\n",
    "r = 0.9\n",
    "utils.split_h5_file(file_path, r)\n",
    "\n",
    "root, ext = os.path.splitext(file_path)\n",
    "split_file1 = root + '_split1' + ext\n",
    "split_file2 = root + '_split2' + ext\n",
    "\n",
    "os.rename(split_file1, './Sample/SPANet/pp6b_4b_PT40_train.h5')\n",
    "os.rename(split_file2, './Sample/SPANet/pp6b_4b_PT40_test.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'./Sample/SPANet/gghhh_4b_PT40_train.h5' and ('./Sample/SPANet/pp6b_4b_PT40_train.h5',) are same structure, can be merged.\n",
      "./Sample/SPANet/gghhh_4b_PT40_train_merged.h5 not exist. Copy ./Sample/SPANet/gghhh_4b_PT40_train.h5 to ./Sample/SPANet/gghhh_4b_PT40_train_merged.h5\n",
      "Size of ./Sample/SPANet/gghhh_4b_PT40_train.h5: 450000\n",
      "Size of ./Sample/SPANet/pp6b_4b_PT40_train.h5: 450000\n",
      "Size of ./Sample/SPANet/gghhh_4b_PT40_train_merged.h5: 900000\n",
      "'./Sample/SPANet/gghhh_4b_PT40_test.h5' and ('./Sample/SPANet/pp6b_4b_PT40_test.h5',) are same structure, can be merged.\n",
      "./Sample/SPANet/gghhh_4b_PT40_test_merged.h5 not exist. Copy ./Sample/SPANet/gghhh_4b_PT40_test.h5 to ./Sample/SPANet/gghhh_4b_PT40_test_merged.h5\n",
      "Size of ./Sample/SPANet/gghhh_4b_PT40_test.h5: 50000\n",
      "Size of ./Sample/SPANet/pp6b_4b_PT40_test.h5: 50000\n",
      "Size of ./Sample/SPANet/gghhh_4b_PT40_test_merged.h5: 100000\n"
     ]
    }
   ],
   "source": [
    "files = ['./Sample/SPANet/gghhh_4b_PT40_train.h5', \n",
    "         './Sample/SPANet/pp6b_4b_PT40_train.h5']\n",
    "\n",
    "merged_h5 = utils.merge_h5_file(*files)\n",
    "\n",
    "new_file = 'Sample/SPANet/triHiggs_4b_PT40_train.h5'\n",
    "\n",
    "os.rename(merged_h5, new_file)\n",
    "\n",
    "files = ['./Sample/SPANet/gghhh_4b_PT40_test.h5', \n",
    "         './Sample/SPANet/pp6b_4b_PT40_test.h5']\n",
    "\n",
    "merged_h5 = utils.merge_h5_file(*files)\n",
    "\n",
    "new_file = 'Sample/SPANet/triHiggs_4b_PT40_test.h5'\n",
    "\n",
    "os.rename(merged_h5, new_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 900000\n",
      "Dataset size: 100000\n"
     ]
    }
   ],
   "source": [
    "utils.shuffle_h5('Sample/SPANet/triHiggs_4b_PT40_train.h5')\n",
    "utils.shuffle_h5('Sample/SPANet/triHiggs_4b_PT40_test.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare training and testing datasets in the $6b$ region "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of Sample/SPANet/gghhh_6b.h5: 486694\n",
      "Size of Sample/SPANet/gghhh_6b_split1.h5: 400000\n",
      "Size of Sample/SPANet/gghhh_6b_split2.h5: 86694\n"
     ]
    }
   ],
   "source": [
    "file_path = 'Sample/SPANet/gghhh_6b.h5'\n",
    "size = 400000\n",
    "utils.split_h5_size(file_path, size)\n",
    "\n",
    "root, ext = os.path.splitext(file_path)\n",
    "split_file1 = root + '_split1' + ext\n",
    "split_file2 = root + '_split2' + ext\n",
    "\n",
    "os.rename(split_file1, './Sample/SPANet/gghhh_6b_PT40.h5')\n",
    "os.rename(split_file2, './Sample/SPANet/gghhh_6b_PT40_DNN.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of ./Sample/SPANet/gghhh_6b_PT40.h5: 400000\n",
      "Size of ./Sample/SPANet/gghhh_6b_PT40_split1.h5: 360000\n",
      "Size of ./Sample/SPANet/gghhh_6b_PT40_split2.h5: 40000\n"
     ]
    }
   ],
   "source": [
    "file_path = './Sample/SPANet/gghhh_6b_PT40.h5'\n",
    "r = 0.9\n",
    "utils.split_h5_file(file_path, r)\n",
    "\n",
    "root, ext = os.path.splitext(file_path)\n",
    "split_file1 = root + '_split1' + ext\n",
    "split_file2 = root + '_split2' + ext\n",
    "\n",
    "os.rename(split_file1, './Sample/SPANet/gghhh_6b_PT40_train.h5')\n",
    "os.rename(split_file2, './Sample/SPANet/gghhh_6b_PT40_test.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./Sample/SPANet/gghhh_6b_PT40_train.h5\n",
      "Dataset size: 360000\n",
      "Number of 0 Higgs events: 4607\n",
      "Number of 1 Higgs events: 38595\n",
      "Number of 2 Higgs events: 73036\n",
      "Number of 3 Higgs events: 243762\n",
      "\\item Total sample size: 360,000\n",
      "\\item 1h sample size: 38,595\n",
      "\\item 2h sample size: 73,036\n",
      "\\item 3h sample size: 243,762\n",
      "Number of 3 Higgs events: 243762\n",
      "./Sample/SPANet/gghhh_6b_PT40_3h_train.h5\n",
      "Dataset size: 243762\n",
      "Number of 0 Higgs events: 0\n",
      "Number of 1 Higgs events: 0\n",
      "Number of 2 Higgs events: 0\n",
      "Number of 3 Higgs events: 243762\n",
      "\\item Total sample size: 243,762\n",
      "\\item 1h sample size: 0\n",
      "\\item 2h sample size: 0\n",
      "\\item 3h sample size: 243,762\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'total': 243762, '0h': 0, '1h': 0, '2h': 0, '3h': 243762}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = './Sample/SPANet/gghhh_6b_PT40_train.h5'\n",
    "print_triHiggs_h5_info(file_path)\n",
    "\n",
    "output_file = './Sample/SPANet/gghhh_6b_PT40_3h_train.h5'\n",
    "triHiggs_file = select_3h_event(file_path, output_file)\n",
    "print_triHiggs_h5_info(triHiggs_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./Sample/SPANet/gghhh_6b_PT40_test.h5\n",
      "Dataset size: 40000\n",
      "Number of 0 Higgs events: 483\n",
      "Number of 1 Higgs events: 4360\n",
      "Number of 2 Higgs events: 8070\n",
      "Number of 3 Higgs events: 27087\n",
      "\\item Total sample size: 40,000\n",
      "\\item 1h sample size: 4,360\n",
      "\\item 2h sample size: 8,070\n",
      "\\item 3h sample size: 27,087\n",
      "Number of 3 Higgs events: 27087\n",
      "./Sample/SPANet/gghhh_6b_PT40_3h_test.h5\n",
      "Dataset size: 27087\n",
      "Number of 0 Higgs events: 0\n",
      "Number of 1 Higgs events: 0\n",
      "Number of 2 Higgs events: 0\n",
      "Number of 3 Higgs events: 27087\n",
      "\\item Total sample size: 27,087\n",
      "\\item 1h sample size: 0\n",
      "\\item 2h sample size: 0\n",
      "\\item 3h sample size: 27,087\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'total': 27087, '0h': 0, '1h': 0, '2h': 0, '3h': 27087}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = './Sample/SPANet/gghhh_6b_PT40_test.h5'\n",
    "print_triHiggs_h5_info(file_path)\n",
    "\n",
    "output_file = './Sample/SPANet/gghhh_6b_PT40_3h_test.h5'\n",
    "triHiggs_file = select_3h_event(file_path, output_file)\n",
    "print_triHiggs_h5_info(triHiggs_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
