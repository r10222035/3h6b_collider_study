{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import utils_HDF5 as utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TriHiggs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_triHiggs_h5_info(file_path):\n",
    "    # 印出 triHiggs HDF5 資料中，各 Higgs 數目的事件數\n",
    "    print(file_path)\n",
    "    with h5py.File(file_path, 'r') as f:\n",
    "\n",
    "        h1b1 = f['TARGETS/h1/b1'][...]\n",
    "        h1b2 = f['TARGETS/h1/b2'][...]\n",
    "        h2b1 = f['TARGETS/h2/b1'][...]\n",
    "        h2b2 = f['TARGETS/h2/b2'][...]\n",
    "        h3b1 = f['TARGETS/h3/b1'][...]\n",
    "        h3b2 = f['TARGETS/h3/b2'][...]\n",
    "\n",
    "        quark_jet = np.array([h1b1, h1b2, h2b1, h2b2, h3b1, h3b2]).T\n",
    "\n",
    "        h1_mask = utils.get_particle_mask(quark_jet, (0, 1))\n",
    "        h2_mask = utils.get_particle_mask(quark_jet, (2, 3))\n",
    "        h3_mask = utils.get_particle_mask(quark_jet, (4, 5))\n",
    "        \n",
    "        n_tot = h1_mask.shape[0]\n",
    "        n_0h = ((~h1_mask) & (~h2_mask) & (~h3_mask)).sum()\n",
    "        # 任一個 Higgs 有對應的 jet\n",
    "        n_1h = ((h1_mask & (~h2_mask) & (~h3_mask)) | \n",
    "                ((~h1_mask) & h2_mask & (~h3_mask)) | \n",
    "                ((~h1_mask) & (~h2_mask) & h3_mask)).sum()\n",
    "        \n",
    "        # 任兩個 Higgs 有對應的 jet\n",
    "        n_2h = ((h1_mask & h2_mask & (~h3_mask)) | \n",
    "                ((~h1_mask) & h2_mask & h3_mask) | \n",
    "                (h1_mask & (~h2_mask) & h3_mask)).sum()\n",
    "        n_3h = (h1_mask & h2_mask & h3_mask).sum()\n",
    "\n",
    "    print(f'Dataset size: {n_tot}')\n",
    "    print(f'Number of 0 Higgs events: {n_0h}')\n",
    "    print(f'Number of 1 Higgs events: {n_1h}')\n",
    "    print(f'Number of 2 Higgs events: {n_2h}')\n",
    "    print(f'Number of 3 Higgs events: {n_3h}')\n",
    "    \n",
    "    print(f'\\\\item Total sample size: {n_tot:,}')\n",
    "    print(f'\\\\item 1h sample size: {n_1h:,}')\n",
    "    print(f'\\\\item 2h sample size: {n_2h:,}')\n",
    "    print(f'\\\\item 3h sample size: {n_3h:,}')\n",
    "    \n",
    "    result = {\n",
    "        'total': n_tot,\n",
    "        '0h': n_0h,\n",
    "        '1h': n_1h,\n",
    "        '2h': n_2h,\n",
    "        '3h': n_3h\n",
    "    }\n",
    "    return result\n",
    "\n",
    "def print_h5_sb_info(file):\n",
    "    # 印出訊號與背景的事件數\n",
    "    with h5py.File(file,'r') as f:\n",
    "        n_tot = f['CLASSIFICATIONS/EVENT/signal'][...].shape[0]\n",
    "        ns = (f['CLASSIFICATIONS/EVENT/signal'][...] == 1).sum()\n",
    "        nb = (f['CLASSIFICATIONS/EVENT/signal'][...] == 0).sum()\n",
    "\n",
    "    print(f'\\\\item Total sample size: {n_tot:,}')\n",
    "    print(f'\\\\item Signal sample size: {ns:,}')\n",
    "    print(f'\\\\item Background sample size: {nb:,}')\n",
    "    \n",
    "\n",
    "def select_3h_event(file, output_file):\n",
    "    # 選取 triHiggs HDF5 資料中，有 3 個 Higgs 的事件\n",
    "    # root, ext = os.path.splitext(file)\n",
    "    # new_file = root + '_3h' + ext\n",
    "\n",
    "    with h5py.File(file, 'r') as f:\n",
    "        h1b1 = f['TARGETS/h1/b1'][...]\n",
    "        h1b2 = f['TARGETS/h1/b2'][...]\n",
    "        h2b1 = f['TARGETS/h2/b1'][...]\n",
    "        h2b2 = f['TARGETS/h2/b2'][...]\n",
    "        h3b1 = f['TARGETS/h3/b1'][...]\n",
    "        h3b2 = f['TARGETS/h3/b2'][...]\n",
    "\n",
    "        quark_jet = np.array([h1b1, h1b2, h2b1, h2b2, h3b1, h3b2]).T\n",
    "\n",
    "        h1_mask = utils.get_particle_mask(quark_jet, (0, 1))\n",
    "        h2_mask = utils.get_particle_mask(quark_jet, (2, 3))\n",
    "        h3_mask = utils.get_particle_mask(quark_jet, (4, 5))\n",
    "        \n",
    "        mask = h1_mask & h2_mask & h3_mask\n",
    "        n_3h = mask.sum()\n",
    "\n",
    "        print(f'Number of 3 Higgs events: {n_3h}')\n",
    "\n",
    "        # copy 3h events to new file\n",
    "        shutil.copyfile(file, output_file)\n",
    "        with h5py.File(output_file, 'a') as f_new:\n",
    "            for key in utils.get_dataset_keys(f):\n",
    "                f_new[key].resize(n_3h, axis=0)\n",
    "                f_new[key][:] = f[key][:][mask]\n",
    "\n",
    "    return output_file\n",
    "\n",
    "def select_nb_event(file, output_file, nb=6):\n",
    "    # 選取 triHiggs HDF5 資料中，有 nb 個 b-jets 的事件\n",
    "    # root, ext = os.path.splitext(file)\n",
    "\n",
    "    with h5py.File(file, 'r') as f:\n",
    "        bTag = f['INPUTS/Source/btag'][...]\n",
    "        n_b_jet = np.sum(bTag, axis=1)\n",
    "\n",
    "        mask = n_b_jet >= nb\n",
    "        n_6b = mask.sum()\n",
    "\n",
    "        print(f'Number of {nb} b events: {n_6b}')\n",
    "\n",
    "        # copy 3h events to new file\n",
    "        shutil.copyfile(file, output_file)\n",
    "        with h5py.File(output_file, 'a') as f_new:\n",
    "            for key in utils.get_dataset_keys(f):\n",
    "                f_new[key].resize(n_6b, axis=0)\n",
    "                f_new[key][:] = f[key][:][mask]\n",
    "\n",
    "    return output_file\n",
    "\n",
    "def select_4pT40_event(file, output_file):\n",
    "    # 選取 triHiggs HDF5 資料中，有 nb 個 b-jets 的事件\n",
    "    # root, ext = os.path.splitext(file)\n",
    "\n",
    "    with h5py.File(file, 'r') as f:\n",
    "        pt = f['INPUTS/Source/pt'][...]\n",
    "        pt_mask = pt[:, 3] > 40\n",
    "\n",
    "        n_event = pt_mask.sum()\n",
    "        print(f'Number of 4 pT > 40 GeV events: {n_event}')\n",
    "\n",
    "        # copy 3h events to new file\n",
    "        shutil.copyfile(file, output_file)\n",
    "        with h5py.File(output_file, 'a') as f_new:\n",
    "            for key in utils.get_dataset_keys(f):\n",
    "                f_new[key].resize(n_event, axis=0)\n",
    "                f_new[key][:] = f[key][:][pt_mask]\n",
    "\n",
    "    return output_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./Sample/SPANet/bkg/pp6b-pT25_0b.h5\n",
      "Dataset size: 5570742\n",
      "CLASSIFICATIONS/EVENT/signal 0\n",
      "INPUTS/Source/MASK [ True  True  True  True  True  True False False False False False False\n",
      " False False False]\n",
      "INPUTS/Source/btag [False  True False False  True  True False False False False False False\n",
      " False False False]\n",
      "INPUTS/Source/eta [-1.5613574   1.7147591   0.50634855 -2.4052203  -2.3219755   1.6762717\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.        ]\n",
      "INPUTS/Source/mass [18.679089   8.476983   9.943685   6.022513   7.6641026  3.0452356\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.       ]\n",
      "INPUTS/Source/phi [ 0.15385643  2.5918746   3.0130267  -1.8666257  -0.7792846   2.0502343\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.        ]\n",
      "INPUTS/Source/pt [80.86402  63.279446 46.487667 33.09533  30.195988 25.177929  0.\n",
      "  0.        0.        0.        0.        0.        0.        0.\n",
      "  0.      ]\n",
      "TARGETS/h1/b1 -1\n",
      "TARGETS/h1/b2 -1\n",
      "TARGETS/h2/b1 -1\n",
      "TARGETS/h2/b2 -1\n",
      "TARGETS/h3/b1 -1\n",
      "TARGETS/h3/b2 -1\n",
      "Number of 4 b events: 2431255\n",
      "./Sample/SPANet/bkg/pp6b-pT25_4b.h5\n",
      "Dataset size: 2431255\n",
      "Number of 0 Higgs events: 2431255\n",
      "Number of 1 Higgs events: 0\n",
      "Number of 2 Higgs events: 0\n",
      "Number of 3 Higgs events: 0\n",
      "\\item Total sample size: 2,431,255\n",
      "\\item 1h sample size: 0\n",
      "\\item 2h sample size: 0\n",
      "\\item 3h sample size: 0\n",
      "Number of 4 pT > 40 GeV events: 2030855\n",
      "./Sample/SPANet/bkg/pp6b-4pT40_4b.h5\n",
      "Dataset size: 2030855\n",
      "Number of 0 Higgs events: 2030855\n",
      "Number of 1 Higgs events: 0\n",
      "Number of 2 Higgs events: 0\n",
      "Number of 3 Higgs events: 0\n",
      "\\item Total sample size: 2,030,855\n",
      "\\item 1h sample size: 0\n",
      "\\item 2h sample size: 0\n",
      "\\item 3h sample size: 0\n",
      "Number of 6 b events: 139246\n",
      "./Sample/SPANet/bkg/pp6b-4pT40_6b.h5\n",
      "Dataset size: 139246\n",
      "Number of 0 Higgs events: 139246\n",
      "Number of 1 Higgs events: 0\n",
      "Number of 2 Higgs events: 0\n",
      "Number of 3 Higgs events: 0\n",
      "\\item Total sample size: 139,246\n",
      "\\item 1h sample size: 0\n",
      "\\item 2h sample size: 0\n",
      "\\item 3h sample size: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'total': 139246, '0h': 139246, '1h': 0, '2h': 0, '3h': 0}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = './Sample/SPANet/bkg/pp6b-pT25_0b.h5'\n",
    "utils.print_h5_info(file_path, 600)\n",
    "\n",
    "output_file = './Sample/SPANet/bkg/pp6b-pT25_4b.h5'\n",
    "four_b_file = select_nb_event(file_path, output_file, nb=4)\n",
    "print_triHiggs_h5_info(four_b_file)\n",
    "\n",
    "output_file = './Sample/SPANet/bkg/pp6b-4pT40_4b.h5'\n",
    "four_pT40_file = select_4pT40_event(four_b_file, output_file)\n",
    "print_triHiggs_h5_info(four_pT40_file)\n",
    "\n",
    "output_file = './Sample/SPANet/bkg/pp6b-4pT40_6b.h5'\n",
    "six_b_file = select_nb_event(four_pT40_file, output_file, nb=6)\n",
    "print_triHiggs_h5_info(six_b_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of 4 b events: 1192477\n",
      "./Sample/SPANet/sig/gghhh_bsm_570_250/gghhh_570_250_4b.h5\n",
      "Dataset size: 1192477\n",
      "Number of 0 Higgs events: 14055\n",
      "Number of 1 Higgs events: 174725\n",
      "Number of 2 Higgs events: 601569\n",
      "Number of 3 Higgs events: 402128\n",
      "\\item Total sample size: 1,192,477\n",
      "\\item 1h sample size: 174,725\n",
      "\\item 2h sample size: 601,569\n",
      "\\item 3h sample size: 402,128\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'total': 1192477, '0h': 14055, '1h': 174725, '2h': 601569, '3h': 402128}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = './Sample/signals_h5/570_250_1192477_fix.h5'\n",
    "output_file = './Sample/SPANet/sig/gghhh_bsm_570_250/gghhh_570_250_4b.h5'\n",
    "four_b_file = select_nb_event(file_path, output_file, nb=4)\n",
    "print_triHiggs_h5_info(four_b_file)\n",
    "\n",
    "# output_file = './Sample/SPANet/gghhh_bsm_570_250/gghhh-4pT40_4b.h5'\n",
    "# four_pT40_file = select_4pT40_event(four_b_file, output_file)\n",
    "# print_triHiggs_h5_info(four_pT40_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./Sample/SPANet/sig/gghhh_4b.h5\n",
      "Dataset size: 3653696\n",
      "CLASSIFICATIONS/EVENT/signal 1\n",
      "INPUTS/Source/MASK [ True  True  True  True  True  True False False False False False False\n",
      " False False False]\n",
      "INPUTS/Source/btag [ True False  True  True  True  True False False False False False False\n",
      " False False False]\n",
      "INPUTS/Source/eta [0.97436297 0.7894716  2.3529906  1.225184   0.7835297  0.6211857\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.        ]\n",
      "INPUTS/Source/mass [17.857948  10.667569   8.483025  11.8251505  5.751204   3.7765465\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.       ]\n",
      "INPUTS/Source/phi [-0.39327845  1.9963444  -0.4675336   2.6990483  -1.6782572   2.7238095\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.        ]\n",
      "INPUTS/Source/pt [103.46912   56.578156  51.16346   42.79874   37.01474   25.889942\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.      ]\n",
      "TARGETS/h1/b1 3\n",
      "TARGETS/h1/b2 0\n",
      "TARGETS/h2/b1 4\n",
      "TARGETS/h2/b2 1\n",
      "TARGETS/h3/b1 5\n",
      "TARGETS/h3/b2 2\n",
      "Number of 4 b events: 3653696\n",
      "./Sample/SPANet/sig/gghhh-4b.h5\n",
      "Dataset size: 3653696\n",
      "Number of 0 Higgs events: 223197\n",
      "Number of 1 Higgs events: 998906\n",
      "Number of 2 Higgs events: 1290603\n",
      "Number of 3 Higgs events: 1140990\n",
      "\\item Total sample size: 3,653,696\n",
      "\\item 1h sample size: 998,906\n",
      "\\item 2h sample size: 1,290,603\n",
      "\\item 3h sample size: 1,140,990\n",
      "Number of 4 pT > 40 GeV events: 3653696\n",
      "./Sample/SPANet/sig/gghhh-4pT40_4b.h5\n",
      "Dataset size: 3653696\n",
      "Number of 0 Higgs events: 223197\n",
      "Number of 1 Higgs events: 998906\n",
      "Number of 2 Higgs events: 1290603\n",
      "Number of 3 Higgs events: 1140990\n",
      "\\item Total sample size: 3,653,696\n",
      "\\item 1h sample size: 998,906\n",
      "\\item 2h sample size: 1,290,603\n",
      "\\item 3h sample size: 1,140,990\n",
      "Number of 6 b events: 451431\n",
      "./Sample/SPANet/sig/gghhh-4pT40_6b.h5\n",
      "Dataset size: 451431\n",
      "Number of 0 Higgs events: 5085\n",
      "Number of 1 Higgs events: 44775\n",
      "Number of 2 Higgs events: 92249\n",
      "Number of 3 Higgs events: 309322\n",
      "\\item Total sample size: 451,431\n",
      "\\item 1h sample size: 44,775\n",
      "\\item 2h sample size: 92,249\n",
      "\\item 3h sample size: 309,322\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'total': 451431, '0h': 5085, '1h': 44775, '2h': 92249, '3h': 309322}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = './Sample/SPANet/sig/gghhh-4pT40_4b.h5'\n",
    "\n",
    "output_file = './Sample/SPANet/sig/gghhh-4pT40_6b.h5'\n",
    "six_b_file = select_nb_event(file_path, output_file, nb=6)\n",
    "print_triHiggs_h5_info(six_b_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./Sample/SPANet/sig/gghhh_bsm_500_275/gghhh-4pT40_4b_20241206_005920.h5\n",
      "Dataset size: 263169\n",
      "CLASSIFICATIONS/EVENT/signal 1\n",
      "INPUTS/Source/MASK [ True  True  True  True  True  True  True  True False False False False\n",
      " False False False]\n",
      "INPUTS/Source/btag [False  True  True  True  True  True False False False False False False\n",
      " False False False]\n",
      "INPUTS/Source/eta [ 1.5676259  -0.7082688  -1.4816394  -0.11534607 -1.3581086  -1.5187671\n",
      "  1.6142794   0.5776378   0.          0.          0.          0.\n",
      "  0.          0.          0.        ]\n",
      "INPUTS/Source/mass [31.525133  40.825253  10.715859  17.185774   6.4766912  6.9549823\n",
      "  5.088252   6.411431   0.         0.         0.         0.\n",
      "  0.         0.         0.       ]\n",
      "INPUTS/Source/phi [-1.0851897   2.2579503   1.7293612  -0.51168835  1.0672604  -1.816191\n",
      " -3.0935354  -0.20700423  0.          0.          0.          0.\n",
      "  0.          0.          0.        ]\n",
      "INPUTS/Source/pt [197.18651  189.17502   84.165276  69.00303   45.805927  27.921621\n",
      "  24.676815  23.79402    0.         0.         0.         0.\n",
      "   0.         0.         0.      ]\n",
      "TARGETS/h1/b1 -1\n",
      "TARGETS/h1/b2 -1\n",
      "TARGETS/h2/b1 -1\n",
      "TARGETS/h2/b2 -1\n",
      "TARGETS/h3/b1 4\n",
      "TARGETS/h3/b2 5\n",
      "Number of 6 b events: 22235\n",
      "./Sample/SPANet/sig/gghhh_bsm_500_275/gghhh-4pT40_6b.h5\n",
      "Dataset size: 22235\n",
      "Number of 0 Higgs events: 577\n",
      "Number of 1 Higgs events: 3497\n",
      "Number of 2 Higgs events: 5723\n",
      "Number of 3 Higgs events: 12438\n",
      "\\item Total sample size: 22,235\n",
      "\\item 1h sample size: 3,497\n",
      "\\item 2h sample size: 5,723\n",
      "\\item 3h sample size: 12,438\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'total': 22235, '0h': 577, '1h': 3497, '2h': 5723, '3h': 12438}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = './Sample/SPANet/sig/gghhh_bsm_500_275/gghhh-4pT40_4b_20241206_005920.h5'\n",
    "utils.print_h5_info(file_path, 600)\n",
    "\n",
    "file_path = './Sample/SPANet/sig/gghhh_bsm_500_275/gghhh-4pT40_4b_20241206_005920.h5'\n",
    "\n",
    "output_file = './Sample/SPANet/sig/gghhh_bsm_500_275/gghhh-4pT40_6b.h5'\n",
    "six_b_file = select_nb_event(file_path, output_file, nb=6)\n",
    "print_triHiggs_h5_info(six_b_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../SPANet2/data/triHiggs/triHiggs-4pT40_4b-train.h5\n",
      "Dataset size: 1800000\n",
      "Number of 0 Higgs events: 954693\n",
      "Number of 1 Higgs events: 246462\n",
      "Number of 2 Higgs events: 318057\n",
      "Number of 3 Higgs events: 280788\n",
      "\\item Total sample size: 1,800,000\n",
      "\\item 1h sample size: 246,462\n",
      "\\item 2h sample size: 318,057\n",
      "\\item 3h sample size: 280,788\n",
      "../SPANet2/data/triHiggs/triHiggs-4pT40_4b-test.h5\n",
      "Dataset size: 200000\n",
      "Number of 0 Higgs events: 106208\n",
      "Number of 1 Higgs events: 27243\n",
      "Number of 2 Higgs events: 35050\n",
      "Number of 3 Higgs events: 31499\n",
      "\\item Total sample size: 200,000\n",
      "\\item 1h sample size: 27,243\n",
      "\\item 2h sample size: 35,050\n",
      "\\item 3h sample size: 31,499\n",
      "\\item Total sample size: 1,800,000\n",
      "\\item Signal sample size: 900,000\n",
      "\\item Background sample size: 900,000\n",
      "\\item Total sample size: 200,000\n",
      "\\item Signal sample size: 100,000\n",
      "\\item Background sample size: 100,000\n"
     ]
    }
   ],
   "source": [
    "print_triHiggs_h5_info('../SPANet2/data/triHiggs/triHiggs-4pT40_4b-train.h5')\n",
    "print_triHiggs_h5_info('../SPANet2/data/triHiggs/triHiggs-4pT40_4b-test.h5')\n",
    "\n",
    "print_h5_sb_info('../SPANet2/data/triHiggs/triHiggs-4pT40_4b-train.h5')\n",
    "print_h5_sb_info('../SPANet2/data/triHiggs/triHiggs-4pT40_4b-test.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../SPANet2.2/data/triHiggs/triHiggs-4pT40_4b-mix-train.h5\n",
      "Dataset size: 1800000\n",
      "Number of 0 Higgs events: 958041\n",
      "Number of 1 Higgs events: 246041\n",
      "Number of 2 Higgs events: 316793\n",
      "Number of 3 Higgs events: 279125\n",
      "\\item Total sample size: 1,800,000\n",
      "\\item 1h sample size: 246,041\n",
      "\\item 2h sample size: 316,793\n",
      "\\item 3h sample size: 279,125\n",
      "../SPANet2.2/data/triHiggs/triHiggs-4pT40_4b-mix-test.h5\n",
      "Dataset size: 200000\n",
      "Number of 0 Higgs events: 106345\n",
      "Number of 1 Higgs events: 27329\n",
      "Number of 2 Higgs events: 35226\n",
      "Number of 3 Higgs events: 31100\n",
      "\\item Total sample size: 200,000\n",
      "\\item 1h sample size: 27,329\n",
      "\\item 2h sample size: 35,226\n",
      "\\item 3h sample size: 31,100\n",
      "\\item Total sample size: 1,800,000\n",
      "\\item Signal sample size: 900,000\n",
      "\\item Background sample size: 900,000\n",
      "\\item Total sample size: 200,000\n",
      "\\item Signal sample size: 100,000\n",
      "\\item Background sample size: 100,000\n"
     ]
    }
   ],
   "source": [
    "print_triHiggs_h5_info('../SPANet2.2/data/triHiggs/triHiggs-4pT40_4b-mix-train.h5')\n",
    "print_triHiggs_h5_info('../SPANet2.2/data/triHiggs/triHiggs-4pT40_4b-mix-test.h5')\n",
    "\n",
    "print_h5_sb_info('../SPANet2.2/data/triHiggs/triHiggs-4pT40_4b-mix-train.h5')\n",
    "print_h5_sb_info('../SPANet2.2/data/triHiggs/triHiggs-4pT40_4b-mix-test.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../SPANet2.3/data/triHiggs/triHiggs_TRSM-4pT40_4b-mix_4-train.h5\n",
      "Dataset size: 1800000\n",
      "Number of 0 Higgs events: 950820\n",
      "Number of 1 Higgs events: 234321\n",
      "Number of 2 Higgs events: 331837\n",
      "Number of 3 Higgs events: 283022\n",
      "\\item Total sample size: 1,800,000\n",
      "\\item 1h sample size: 234,321\n",
      "\\item 2h sample size: 331,837\n",
      "\\item 3h sample size: 283,022\n",
      "../SPANet2.3/data/triHiggs/triHiggs_TRSM-4pT40_4b-mix_4-test.h5\n",
      "Dataset size: 200000\n",
      "Number of 0 Higgs events: 104772\n",
      "Number of 1 Higgs events: 24744\n",
      "Number of 2 Higgs events: 38116\n",
      "Number of 3 Higgs events: 32368\n",
      "\\item Total sample size: 200,000\n",
      "\\item 1h sample size: 24,744\n",
      "\\item 2h sample size: 38,116\n",
      "\\item 3h sample size: 32,368\n",
      "\\item Total sample size: 1,800,000\n",
      "\\item Signal sample size: 900,000\n",
      "\\item Background sample size: 900,000\n",
      "\\item Total sample size: 200,000\n",
      "\\item Signal sample size: 100,000\n",
      "\\item Background sample size: 100,000\n"
     ]
    }
   ],
   "source": [
    "print_triHiggs_h5_info('../SPANet2.3/data/triHiggs/triHiggs_TRSM-4pT40_4b-mix_4-train.h5')\n",
    "print_triHiggs_h5_info('../SPANet2.3/data/triHiggs/triHiggs_TRSM-4pT40_4b-mix_4-test.h5')\n",
    "\n",
    "print_h5_sb_info('../SPANet2.3/data/triHiggs/triHiggs_TRSM-4pT40_4b-mix_4-train.h5')\n",
    "print_h5_sb_info('../SPANet2.3/data/triHiggs/triHiggs_TRSM-4pT40_4b-mix_4-test.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./Sample/SPANet/sig/gghhh_bsm_570_250/delphes_events_20241226_175330.h5\n",
      "Dataset size: 423448\n",
      "CLASSIFICATIONS/EVENT/signal 1\n",
      "INPUTS/Source/MASK [ True  True  True  True  True  True  True False False False False False\n",
      " False False False]\n",
      "INPUTS/Source/btag [ True  True False  True False  True  True False False False False False\n",
      " False False False]\n",
      "INPUTS/Source/eta [ 0.1386547  -0.5504687  -0.7677351  -1.0969951  -0.85081923 -1.2476897\n",
      " -1.1906663   0.          0.          0.          0.          0.\n",
      "  0.          0.          0.        ]\n",
      "INPUTS/Source/mass [13.674232  15.549836  10.475461   7.7784557  6.708787   9.658851\n",
      "  4.7329345  0.         0.         0.         0.         0.\n",
      "  0.         0.         0.       ]\n",
      "INPUTS/Source/phi [-1.6626706   0.78136003  1.1796929  -2.194342   -1.18122     2.4228196\n",
      "  0.45473677  0.          0.          0.          0.          0.\n",
      "  0.          0.          0.        ]\n",
      "INPUTS/Source/pt [125.52984  117.52345  108.345436  57.491123  43.42492   41.985878\n",
      "  23.134405   0.         0.         0.         0.         0.\n",
      "   0.         0.         0.      ]\n",
      "TARGETS/h1/b1 -1\n",
      "TARGETS/h1/b2 -1\n",
      "TARGETS/h2/b1 5\n",
      "TARGETS/h2/b2 1\n",
      "TARGETS/h3/b1 0\n",
      "TARGETS/h3/b2 3\n"
     ]
    }
   ],
   "source": [
    "utils.print_h5_info('./Sample/SPANet/sig/gghhh_bsm_570_250/delphes_events_20241226_175330.h5', 423440)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Sample/SPANet/gghhh_0b_02.h5' and ('Sample/SPANet/gghhh_0b_03.h5', 'Sample/SPANet/gghhh_0b_04.h5', 'Sample/SPANet/gghhh_0b_05.h5', 'Sample/SPANet/gghhh_0b_06.h5', 'Sample/SPANet/gghhh_0b_07.h5', 'Sample/SPANet/gghhh_0b_08.h5', 'Sample/SPANet/gghhh_0b_323.h5', 'Sample/SPANet/gghhh_0b_423.h5', 'Sample/SPANet/gghhh_0b_523.h5', 'Sample/SPANet/gghhh_0b_614.h5', 'Sample/SPANet/gghhh_0b_714.h5') are same structure, can be merged.\n",
      "Sample/SPANet/gghhh_0b_02_merged.h5 not exist. Copy Sample/SPANet/gghhh_0b_02.h5 to Sample/SPANet/gghhh_0b_02_merged.h5\n",
      "Size of Sample/SPANet/gghhh_0b_02.h5: 304372\n",
      "Size of Sample/SPANet/gghhh_0b_03.h5: 303994\n",
      "Size of Sample/SPANet/gghhh_0b_02_merged.h5: 608366\n",
      "Size of Sample/SPANet/gghhh_0b_04.h5: 303915\n",
      "Size of Sample/SPANet/gghhh_0b_02_merged.h5: 912281\n",
      "Size of Sample/SPANet/gghhh_0b_05.h5: 304049\n",
      "Size of Sample/SPANet/gghhh_0b_02_merged.h5: 1216330\n",
      "Size of Sample/SPANet/gghhh_0b_06.h5: 304151\n",
      "Size of Sample/SPANet/gghhh_0b_02_merged.h5: 1520481\n",
      "Size of Sample/SPANet/gghhh_0b_07.h5: 304332\n",
      "Size of Sample/SPANet/gghhh_0b_02_merged.h5: 1824813\n",
      "Size of Sample/SPANet/gghhh_0b_08.h5: 305061\n",
      "Size of Sample/SPANet/gghhh_0b_02_merged.h5: 2129874\n",
      "Size of Sample/SPANet/gghhh_0b_323.h5: 304491\n",
      "Size of Sample/SPANet/gghhh_0b_02_merged.h5: 2434365\n",
      "Size of Sample/SPANet/gghhh_0b_423.h5: 305197\n",
      "Size of Sample/SPANet/gghhh_0b_02_merged.h5: 2739562\n",
      "Size of Sample/SPANet/gghhh_0b_523.h5: 304733\n",
      "Size of Sample/SPANet/gghhh_0b_02_merged.h5: 3044295\n",
      "Size of Sample/SPANet/gghhh_0b_614.h5: 304689\n",
      "Size of Sample/SPANet/gghhh_0b_02_merged.h5: 3348984\n",
      "Size of Sample/SPANet/gghhh_0b_714.h5: 304712\n",
      "Size of Sample/SPANet/gghhh_0b_02_merged.h5: 3653696\n"
     ]
    }
   ],
   "source": [
    "files = [f'Sample/SPANet/gghhh_0b_{i:02}.h5' for i in range(2, 9)] + [f'Sample/SPANet/gghhh_0b_{rnd}.h5' for rnd in [323, 423, 523, 614, 714]]\n",
    "\n",
    "merged_h5 = utils.merge_h5_file(*files)\n",
    "\n",
    "new_file = 'Sample/SPANet/gghhh_4b.h5'\n",
    "\n",
    "os.rename(merged_h5, new_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Sample/SPANet/gghhh_6b_02.h5' and ('Sample/SPANet/gghhh_6b_03.h5', 'Sample/SPANet/gghhh_6b_04.h5', 'Sample/SPANet/gghhh_6b_05.h5', 'Sample/SPANet/gghhh_6b_06.h5', 'Sample/SPANet/gghhh_6b_07.h5', 'Sample/SPANet/gghhh_6b_08.h5', 'Sample/SPANet/gghhh_6b_323.h5', 'Sample/SPANet/gghhh_6b_423.h5', 'Sample/SPANet/gghhh_6b_523.h5', 'Sample/SPANet/gghhh_6b_614.h5', 'Sample/SPANet/gghhh_6b_714.h5') are same structure, can be merged.\n",
      "Sample/SPANet/gghhh_6b_02_merged.h5 not exist. Copy Sample/SPANet/gghhh_6b_02.h5 to Sample/SPANet/gghhh_6b_02_merged.h5\n",
      "Size of Sample/SPANet/gghhh_6b_02.h5: 40565\n",
      "Size of Sample/SPANet/gghhh_6b_03.h5: 40866\n",
      "Size of Sample/SPANet/gghhh_6b_02_merged.h5: 81431\n",
      "Size of Sample/SPANet/gghhh_6b_04.h5: 40383\n",
      "Size of Sample/SPANet/gghhh_6b_02_merged.h5: 121814\n",
      "Size of Sample/SPANet/gghhh_6b_05.h5: 40879\n",
      "Size of Sample/SPANet/gghhh_6b_02_merged.h5: 162693\n",
      "Size of Sample/SPANet/gghhh_6b_06.h5: 40538\n",
      "Size of Sample/SPANet/gghhh_6b_02_merged.h5: 203231\n",
      "Size of Sample/SPANet/gghhh_6b_07.h5: 40489\n",
      "Size of Sample/SPANet/gghhh_6b_02_merged.h5: 243720\n",
      "Size of Sample/SPANet/gghhh_6b_08.h5: 40675\n",
      "Size of Sample/SPANet/gghhh_6b_02_merged.h5: 284395\n",
      "Size of Sample/SPANet/gghhh_6b_323.h5: 40256\n",
      "Size of Sample/SPANet/gghhh_6b_02_merged.h5: 324651\n",
      "Size of Sample/SPANet/gghhh_6b_423.h5: 40432\n",
      "Size of Sample/SPANet/gghhh_6b_02_merged.h5: 365083\n",
      "Size of Sample/SPANet/gghhh_6b_523.h5: 40623\n",
      "Size of Sample/SPANet/gghhh_6b_02_merged.h5: 405706\n",
      "Size of Sample/SPANet/gghhh_6b_614.h5: 40203\n",
      "Size of Sample/SPANet/gghhh_6b_02_merged.h5: 445909\n",
      "Size of Sample/SPANet/gghhh_6b_714.h5: 40785\n",
      "Size of Sample/SPANet/gghhh_6b_02_merged.h5: 486694\n"
     ]
    }
   ],
   "source": [
    "files = [f'Sample/SPANet/gghhh_6b_{i:02}.h5' for i in range(2, 9)] + [f'Sample/SPANet/gghhh_6b_{rnd}.h5' for rnd in [323, 423, 523, 614, 714]]\n",
    "\n",
    "merged_h5 = utils.merge_h5_file(*files)\n",
    "\n",
    "new_file = 'Sample/SPANet/gghhh_6b.h5'\n",
    "\n",
    "os.rename(merged_h5, new_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make training and testing dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of ./Sample/SPANet/bkg/pp6b-4pT40_4b.h5: 2030855\n",
      "Size of ./Sample/SPANet/bkg/pp6b-4pT40_4b_split1.h5: 1000000\n",
      "Size of ./Sample/SPANet/bkg/pp6b-4pT40_4b_split2.h5: 1030855\n"
     ]
    }
   ],
   "source": [
    "file_path = './Sample/SPANet/bkg/pp6b-4pT40_4b.h5'\n",
    "size = 1000000\n",
    "utils.split_h5_size(file_path, size)\n",
    "\n",
    "root, ext = os.path.splitext(file_path)\n",
    "split_file1 = root + '_split1' + ext\n",
    "split_file2 = root + '_split2' + ext\n",
    "\n",
    "os.rename(split_file1, './Sample/SPANet/bkg/pp6b-4pT40_4b-1.h5')\n",
    "os.rename(split_file2, './Sample/SPANet/bkg/pp6b-4pT40_4b-2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of ./Sample/SPANet/bkg/pp6b-4pT40_4b-1.h5: 1000000\n",
      "Size of ./Sample/SPANet/bkg/pp6b-4pT40_4b-1_split1.h5: 900000\n",
      "Size of ./Sample/SPANet/bkg/pp6b-4pT40_4b-1_split2.h5: 100000\n"
     ]
    }
   ],
   "source": [
    "file_path = './Sample/SPANet/bkg/pp6b-4pT40_4b-1.h5'\n",
    "size = 900000\n",
    "utils.split_h5_size(file_path, size)\n",
    "\n",
    "root, ext = os.path.splitext(file_path)\n",
    "split_file1 = root + '_split1' + ext\n",
    "split_file2 = root + '_split2' + ext\n",
    "\n",
    "os.rename(split_file1, './Sample/SPANet/bkg/pp6b-4pT40_4b-train.h5')\n",
    "os.rename(split_file2, './Sample/SPANet/bkg/pp6b-4pT40_4b-test.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of 6 b events: 70848\n",
      "./Sample/SPANet/bkg/pp6b-4pT40_6b.h5\n",
      "Dataset size: 70848\n",
      "Number of 0 Higgs events: 70848\n",
      "Number of 1 Higgs events: 0\n",
      "Number of 2 Higgs events: 0\n",
      "Number of 3 Higgs events: 0\n",
      "\\item Total sample size: 70,848\n",
      "\\item 1h sample size: 0\n",
      "\\item 2h sample size: 0\n",
      "\\item 3h sample size: 0\n",
      "Size of ./Sample/SPANet/bkg/pp6b-4pT40_6b.h5: 70848\n",
      "Size of ./Sample/SPANet/bkg/pp6b-4pT40_6b_split1.h5: 50000\n",
      "Size of ./Sample/SPANet/bkg/pp6b-4pT40_6b_split2.h5: 20848\n"
     ]
    }
   ],
   "source": [
    "output_file = './Sample/SPANet/bkg/pp6b-4pT40_6b.h5'\n",
    "six_b_file = select_nb_event('./Sample/SPANet/bkg/pp6b-4pT40_4b-2.h5', output_file, nb=6)\n",
    "print_triHiggs_h5_info(six_b_file)\n",
    "\n",
    "size = 50000\n",
    "utils.split_h5_size(six_b_file, size)\n",
    "\n",
    "root, ext = os.path.splitext(six_b_file)\n",
    "split_file1 = root + '_split1' + ext\n",
    "split_file2 = root + '_split2' + ext\n",
    "\n",
    "os.rename(split_file1, './Sample/SPANet/bkg/pp6b-4pT40_6b-1.h5')\n",
    "os.rename(split_file2, './Sample/SPANet/bkg/pp6b-4pT40_6b-2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DM-CPV Signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'./Sample/SPANet/sig/gghhh_bsm_500_275/delphes_events_20241206_005920.h5' and ('./Sample/SPANet/sig/gghhh_bsm_500_275/delphes_events_20241206_191926.h5',) are same structure, can be merged.\n",
      "./Sample/SPANet/sig/gghhh_bsm_500_275/delphes_events_20241206_005920_merged.h5 not exist. Copy ./Sample/SPANet/sig/gghhh_bsm_500_275/delphes_events_20241206_005920.h5 to ./Sample/SPANet/sig/gghhh_bsm_500_275/delphes_events_20241206_005920_merged.h5\n",
      "Size of ./Sample/SPANet/sig/gghhh_bsm_500_275/delphes_events_20241206_005920.h5: 263169\n",
      "Size of ./Sample/SPANet/sig/gghhh_bsm_500_275/delphes_events_20241206_191926.h5: 397665\n",
      "Size of ./Sample/SPANet/sig/gghhh_bsm_500_275/delphes_events_20241206_005920_merged.h5: 660834\n",
      "'./Sample/SPANet/sig/gghhh_bsm_500_300/delphes_events_20241209_222922.h5' and ('./Sample/SPANet/sig/gghhh_bsm_500_300/delphes_events_20241206_025512.h5',) are same structure, can be merged.\n",
      "./Sample/SPANet/sig/gghhh_bsm_500_300/delphes_events_20241209_222922_merged.h5 not exist. Copy ./Sample/SPANet/sig/gghhh_bsm_500_300/delphes_events_20241209_222922.h5 to ./Sample/SPANet/sig/gghhh_bsm_500_300/delphes_events_20241209_222922_merged.h5\n",
      "Size of ./Sample/SPANet/sig/gghhh_bsm_500_300/delphes_events_20241209_222922.h5: 403190\n",
      "Size of ./Sample/SPANet/sig/gghhh_bsm_500_300/delphes_events_20241206_025512.h5: 300697\n",
      "Size of ./Sample/SPANet/sig/gghhh_bsm_500_300/delphes_events_20241209_222922_merged.h5: 703887\n",
      "'./Sample/SPANet/sig/gghhh_bsm_520_325/delphes_events_20241206_182813.h5' and ('./Sample/SPANet/sig/gghhh_bsm_520_325/delphes_events_20241209_221730.h5',) are same structure, can be merged.\n",
      "./Sample/SPANet/sig/gghhh_bsm_520_325/delphes_events_20241206_182813_merged.h5 not exist. Copy ./Sample/SPANet/sig/gghhh_bsm_520_325/delphes_events_20241206_182813.h5 to ./Sample/SPANet/sig/gghhh_bsm_520_325/delphes_events_20241206_182813_merged.h5\n",
      "Size of ./Sample/SPANet/sig/gghhh_bsm_520_325/delphes_events_20241206_182813.h5: 317544\n",
      "Size of ./Sample/SPANet/sig/gghhh_bsm_520_325/delphes_events_20241209_221730.h5: 420580\n",
      "Size of ./Sample/SPANet/sig/gghhh_bsm_520_325/delphes_events_20241206_182813_merged.h5: 738124\n",
      "'./Sample/SPANet/sig/gghhh_bsm_570_250/delphes_events_20241228_015103.h5' and () are same structure, can be merged.\n",
      "./Sample/SPANet/sig/gghhh_bsm_570_250/delphes_events_20241228_015103_merged.h5 not exist. Copy ./Sample/SPANet/sig/gghhh_bsm_570_250/delphes_events_20241228_015103.h5 to ./Sample/SPANet/sig/gghhh_bsm_570_250/delphes_events_20241228_015103_merged.h5\n",
      "Size of ./Sample/SPANet/sig/gghhh_bsm_570_250/delphes_events_20241228_015103.h5: 424764\n",
      "'./Sample/SPANet/sig/gghhh_bsm_600_325/delphes_events_20241220_041419.h5' and () are same structure, can be merged.\n",
      "./Sample/SPANet/sig/gghhh_bsm_600_325/delphes_events_20241220_041419_merged.h5 not exist. Copy ./Sample/SPANet/sig/gghhh_bsm_600_325/delphes_events_20241220_041419.h5 to ./Sample/SPANet/sig/gghhh_bsm_600_325/delphes_events_20241220_041419_merged.h5\n",
      "Size of ./Sample/SPANet/sig/gghhh_bsm_600_325/delphes_events_20241220_041419.h5: 483595\n",
      "'./Sample/SPANet/sig/gghhh_bsm_700_325/delphes_events_20241220_013311.h5' and () are same structure, can be merged.\n",
      "./Sample/SPANet/sig/gghhh_bsm_700_325/delphes_events_20241220_013311_merged.h5 not exist. Copy ./Sample/SPANet/sig/gghhh_bsm_700_325/delphes_events_20241220_013311.h5 to ./Sample/SPANet/sig/gghhh_bsm_700_325/delphes_events_20241220_013311_merged.h5\n",
      "Size of ./Sample/SPANet/sig/gghhh_bsm_700_325/delphes_events_20241220_013311.h5: 466599\n",
      "'./Sample/SPANet/sig/gghhh_bsm_800_325/delphes_events_20241223_180653.h5' and () are same structure, can be merged.\n",
      "./Sample/SPANet/sig/gghhh_bsm_800_325/delphes_events_20241223_180653_merged.h5 not exist. Copy ./Sample/SPANet/sig/gghhh_bsm_800_325/delphes_events_20241223_180653.h5 to ./Sample/SPANet/sig/gghhh_bsm_800_325/delphes_events_20241223_180653_merged.h5\n",
      "Size of ./Sample/SPANet/sig/gghhh_bsm_800_325/delphes_events_20241223_180653.h5: 459197\n",
      "'./Sample/SPANet/sig/gghhh_bsm_700_400/delphes_events_20241223_220556.h5' and () are same structure, can be merged.\n",
      "./Sample/SPANet/sig/gghhh_bsm_700_400/delphes_events_20241223_220556_merged.h5 not exist. Copy ./Sample/SPANet/sig/gghhh_bsm_700_400/delphes_events_20241223_220556.h5 to ./Sample/SPANet/sig/gghhh_bsm_700_400/delphes_events_20241223_220556_merged.h5\n",
      "Size of ./Sample/SPANet/sig/gghhh_bsm_700_400/delphes_events_20241223_220556.h5: 519502\n",
      "'./Sample/SPANet/sig/gghhh_bsm_800_400/delphes_events_20241223_185321.h5' and () are same structure, can be merged.\n",
      "./Sample/SPANet/sig/gghhh_bsm_800_400/delphes_events_20241223_185321_merged.h5 not exist. Copy ./Sample/SPANet/sig/gghhh_bsm_800_400/delphes_events_20241223_185321.h5 to ./Sample/SPANet/sig/gghhh_bsm_800_400/delphes_events_20241223_185321_merged.h5\n",
      "Size of ./Sample/SPANet/sig/gghhh_bsm_800_400/delphes_events_20241223_185321.h5: 500610\n"
     ]
    }
   ],
   "source": [
    "# merge all .h5 files in the folder\n",
    "# for m3_m2 in ['500_275', '500_300', '520_325']:\n",
    "for m3_m2 in ['500_275', '500_300', '520_325', '570_250', '600_325', '700_325', '800_325', '700_400', '800_400']:\n",
    "    files_path = f'./Sample/SPANet/sig/gghhh_bsm_{m3_m2}/'\n",
    "    files = [os.path.join(files_path, name) for name in os.listdir(files_path) if name.startswith('delphes_events_')]\n",
    "    merged_h5 = utils.merge_h5_file(*files)\n",
    "\n",
    "    new_file = f'./Sample/SPANet/sig/gghhh_bsm_{m3_m2}/gghhh-4pT40_4b.h5'\n",
    "    os.rename(merged_h5, new_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m3_m2 in ['570_250', '600_325', '700_325', '800_325', '700_400', '800_400']:\n",
    "    file_name = f'./Sample/45b_400k/{m3_m2}_45b_400000.h5'\n",
    "    new_file = f'./Sample/SPANet/sig/gghhh_bsm_{m3_m2}/gghhh-4pT40_4b.h5'\n",
    "    # copy 3h events to new file\n",
    "    shutil.copyfile(file_name, new_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of Sample/SPANet/sig/gghhh_bsm_570_250/gghhh-4pT40_4b.h5: 400000\n",
      "Size of Sample/SPANet/sig/gghhh_bsm_570_250/gghhh-4pT40_4b_split1.h5: 83333\n",
      "Size of Sample/SPANet/sig/gghhh_bsm_570_250/gghhh-4pT40_4b_split2.h5: 316667\n",
      "Size of Sample/SPANet/sig/gghhh_bsm_570_250/gghhh-4pT40_4b-1.h5: 83333\n",
      "Size of Sample/SPANet/sig/gghhh_bsm_570_250/gghhh-4pT40_4b-1_split1.h5: 74999\n",
      "Size of Sample/SPANet/sig/gghhh_bsm_570_250/gghhh-4pT40_4b-1_split2.h5: 8334\n",
      "Number of 6 b events: 0\n",
      "Sample/SPANet/sig/gghhh_bsm_570_250/gghhh-4pT40_6b.h5\n",
      "Dataset size: 0\n",
      "Number of 0 Higgs events: 0\n",
      "Number of 1 Higgs events: 0\n",
      "Number of 2 Higgs events: 0\n",
      "Number of 3 Higgs events: 0\n",
      "\\item Total sample size: 0\n",
      "\\item 1h sample size: 0\n",
      "\\item 2h sample size: 0\n",
      "\\item 3h sample size: 0\n",
      "Size of Sample/SPANet/sig/gghhh_bsm_570_250/gghhh-4pT40_6b.h5: 0\n",
      "Split size 8333 is greater than the input file size 0.\n",
      "Size of Sample/SPANet/sig/gghhh_bsm_570_250/gghhh-4pT40_6b_split1.h5: 0\n",
      "Size of Sample/SPANet/sig/gghhh_bsm_570_250/gghhh-4pT40_6b_split2.h5: 0\n",
      "Size of Sample/SPANet/sig/gghhh_bsm_600_325/gghhh-4pT40_4b.h5: 400000\n",
      "Size of Sample/SPANet/sig/gghhh_bsm_600_325/gghhh-4pT40_4b_split1.h5: 83333\n",
      "Size of Sample/SPANet/sig/gghhh_bsm_600_325/gghhh-4pT40_4b_split2.h5: 316667\n",
      "Size of Sample/SPANet/sig/gghhh_bsm_600_325/gghhh-4pT40_4b-1.h5: 83333\n",
      "Size of Sample/SPANet/sig/gghhh_bsm_600_325/gghhh-4pT40_4b-1_split1.h5: 74999\n",
      "Size of Sample/SPANet/sig/gghhh_bsm_600_325/gghhh-4pT40_4b-1_split2.h5: 8334\n",
      "Number of 6 b events: 0\n",
      "Sample/SPANet/sig/gghhh_bsm_600_325/gghhh-4pT40_6b.h5\n",
      "Dataset size: 0\n",
      "Number of 0 Higgs events: 0\n",
      "Number of 1 Higgs events: 0\n",
      "Number of 2 Higgs events: 0\n",
      "Number of 3 Higgs events: 0\n",
      "\\item Total sample size: 0\n",
      "\\item 1h sample size: 0\n",
      "\\item 2h sample size: 0\n",
      "\\item 3h sample size: 0\n",
      "Size of Sample/SPANet/sig/gghhh_bsm_600_325/gghhh-4pT40_6b.h5: 0\n",
      "Split size 8333 is greater than the input file size 0.\n",
      "Size of Sample/SPANet/sig/gghhh_bsm_600_325/gghhh-4pT40_6b_split1.h5: 0\n",
      "Size of Sample/SPANet/sig/gghhh_bsm_600_325/gghhh-4pT40_6b_split2.h5: 0\n",
      "Size of Sample/SPANet/sig/gghhh_bsm_700_325/gghhh-4pT40_4b.h5: 400000\n",
      "Size of Sample/SPANet/sig/gghhh_bsm_700_325/gghhh-4pT40_4b_split1.h5: 83333\n",
      "Size of Sample/SPANet/sig/gghhh_bsm_700_325/gghhh-4pT40_4b_split2.h5: 316667\n",
      "Size of Sample/SPANet/sig/gghhh_bsm_700_325/gghhh-4pT40_4b-1.h5: 83333\n",
      "Size of Sample/SPANet/sig/gghhh_bsm_700_325/gghhh-4pT40_4b-1_split1.h5: 74999\n",
      "Size of Sample/SPANet/sig/gghhh_bsm_700_325/gghhh-4pT40_4b-1_split2.h5: 8334\n",
      "Number of 6 b events: 0\n",
      "Sample/SPANet/sig/gghhh_bsm_700_325/gghhh-4pT40_6b.h5\n",
      "Dataset size: 0\n",
      "Number of 0 Higgs events: 0\n",
      "Number of 1 Higgs events: 0\n",
      "Number of 2 Higgs events: 0\n",
      "Number of 3 Higgs events: 0\n",
      "\\item Total sample size: 0\n",
      "\\item 1h sample size: 0\n",
      "\\item 2h sample size: 0\n",
      "\\item 3h sample size: 0\n",
      "Size of Sample/SPANet/sig/gghhh_bsm_700_325/gghhh-4pT40_6b.h5: 0\n",
      "Split size 8333 is greater than the input file size 0.\n",
      "Size of Sample/SPANet/sig/gghhh_bsm_700_325/gghhh-4pT40_6b_split1.h5: 0\n",
      "Size of Sample/SPANet/sig/gghhh_bsm_700_325/gghhh-4pT40_6b_split2.h5: 0\n",
      "Size of Sample/SPANet/sig/gghhh_bsm_800_325/gghhh-4pT40_4b.h5: 400000\n",
      "Size of Sample/SPANet/sig/gghhh_bsm_800_325/gghhh-4pT40_4b_split1.h5: 83333\n",
      "Size of Sample/SPANet/sig/gghhh_bsm_800_325/gghhh-4pT40_4b_split2.h5: 316667\n",
      "Size of Sample/SPANet/sig/gghhh_bsm_800_325/gghhh-4pT40_4b-1.h5: 83333\n",
      "Size of Sample/SPANet/sig/gghhh_bsm_800_325/gghhh-4pT40_4b-1_split1.h5: 74999\n",
      "Size of Sample/SPANet/sig/gghhh_bsm_800_325/gghhh-4pT40_4b-1_split2.h5: 8334\n",
      "Number of 6 b events: 0\n",
      "Sample/SPANet/sig/gghhh_bsm_800_325/gghhh-4pT40_6b.h5\n",
      "Dataset size: 0\n",
      "Number of 0 Higgs events: 0\n",
      "Number of 1 Higgs events: 0\n",
      "Number of 2 Higgs events: 0\n",
      "Number of 3 Higgs events: 0\n",
      "\\item Total sample size: 0\n",
      "\\item 1h sample size: 0\n",
      "\\item 2h sample size: 0\n",
      "\\item 3h sample size: 0\n",
      "Size of Sample/SPANet/sig/gghhh_bsm_800_325/gghhh-4pT40_6b.h5: 0\n",
      "Split size 8333 is greater than the input file size 0.\n",
      "Size of Sample/SPANet/sig/gghhh_bsm_800_325/gghhh-4pT40_6b_split1.h5: 0\n",
      "Size of Sample/SPANet/sig/gghhh_bsm_800_325/gghhh-4pT40_6b_split2.h5: 0\n",
      "Size of Sample/SPANet/sig/gghhh_bsm_700_400/gghhh-4pT40_4b.h5: 400000\n",
      "Size of Sample/SPANet/sig/gghhh_bsm_700_400/gghhh-4pT40_4b_split1.h5: 83333\n",
      "Size of Sample/SPANet/sig/gghhh_bsm_700_400/gghhh-4pT40_4b_split2.h5: 316667\n",
      "Size of Sample/SPANet/sig/gghhh_bsm_700_400/gghhh-4pT40_4b-1.h5: 83333\n",
      "Size of Sample/SPANet/sig/gghhh_bsm_700_400/gghhh-4pT40_4b-1_split1.h5: 74999\n",
      "Size of Sample/SPANet/sig/gghhh_bsm_700_400/gghhh-4pT40_4b-1_split2.h5: 8334\n",
      "Number of 6 b events: 0\n",
      "Sample/SPANet/sig/gghhh_bsm_700_400/gghhh-4pT40_6b.h5\n",
      "Dataset size: 0\n",
      "Number of 0 Higgs events: 0\n",
      "Number of 1 Higgs events: 0\n",
      "Number of 2 Higgs events: 0\n",
      "Number of 3 Higgs events: 0\n",
      "\\item Total sample size: 0\n",
      "\\item 1h sample size: 0\n",
      "\\item 2h sample size: 0\n",
      "\\item 3h sample size: 0\n",
      "Size of Sample/SPANet/sig/gghhh_bsm_700_400/gghhh-4pT40_6b.h5: 0\n",
      "Split size 8333 is greater than the input file size 0.\n",
      "Size of Sample/SPANet/sig/gghhh_bsm_700_400/gghhh-4pT40_6b_split1.h5: 0\n",
      "Size of Sample/SPANet/sig/gghhh_bsm_700_400/gghhh-4pT40_6b_split2.h5: 0\n",
      "Size of Sample/SPANet/sig/gghhh_bsm_800_400/gghhh-4pT40_4b.h5: 400000\n",
      "Size of Sample/SPANet/sig/gghhh_bsm_800_400/gghhh-4pT40_4b_split1.h5: 83333\n",
      "Size of Sample/SPANet/sig/gghhh_bsm_800_400/gghhh-4pT40_4b_split2.h5: 316667\n",
      "Size of Sample/SPANet/sig/gghhh_bsm_800_400/gghhh-4pT40_4b-1.h5: 83333\n",
      "Size of Sample/SPANet/sig/gghhh_bsm_800_400/gghhh-4pT40_4b-1_split1.h5: 74999\n",
      "Size of Sample/SPANet/sig/gghhh_bsm_800_400/gghhh-4pT40_4b-1_split2.h5: 8334\n",
      "Number of 6 b events: 0\n",
      "Sample/SPANet/sig/gghhh_bsm_800_400/gghhh-4pT40_6b.h5\n",
      "Dataset size: 0\n",
      "Number of 0 Higgs events: 0\n",
      "Number of 1 Higgs events: 0\n",
      "Number of 2 Higgs events: 0\n",
      "Number of 3 Higgs events: 0\n",
      "\\item Total sample size: 0\n",
      "\\item 1h sample size: 0\n",
      "\\item 2h sample size: 0\n",
      "\\item 3h sample size: 0\n",
      "Size of Sample/SPANet/sig/gghhh_bsm_800_400/gghhh-4pT40_6b.h5: 0\n",
      "Split size 8333 is greater than the input file size 0.\n",
      "Size of Sample/SPANet/sig/gghhh_bsm_800_400/gghhh-4pT40_6b_split1.h5: 0\n",
      "Size of Sample/SPANet/sig/gghhh_bsm_800_400/gghhh-4pT40_6b_split2.h5: 0\n"
     ]
    }
   ],
   "source": [
    "# m3_m2_list = ['420_280','500_275', '500_300', '520_325']\n",
    "m3_m2_list = ['420_280', '500_275', '500_300', '520_325',\n",
    "              '570_250', '600_325', '700_325',\n",
    "              '800_325', '700_400', '800_400'\n",
    "              ]\n",
    "n_mass = len(m3_m2_list)\n",
    "n_4b_total = 500000\n",
    "for m3_m2 in m3_m2_list:\n",
    "\n",
    "    # split signal files for 4b and 6b\n",
    "    file_dir = Path(f'./Sample/SPANet/sig/gghhh_bsm_{m3_m2}/')\n",
    "    file_path = file_dir / 'gghhh-4pT40_4b.h5'\n",
    "    size = n_4b_total // n_mass\n",
    "    utils.split_h5_size(file_path, size)\n",
    "\n",
    "    root, ext = os.path.splitext(file_path)\n",
    "    split_file1 = root + '_split1' + ext\n",
    "    split_file2 = root + '_split2' + ext\n",
    "\n",
    "    os.rename(split_file1, file_dir / 'gghhh-4pT40_4b-1.h5')\n",
    "    os.rename(split_file2, file_dir / 'gghhh-4pT40_4b-2.h5')\n",
    "\n",
    "    file_path = file_dir / 'gghhh-4pT40_4b-1.h5'\n",
    "    size = int(n_4b_total // n_mass * 0.9)\n",
    "    utils.split_h5_size(file_path, size)\n",
    "\n",
    "    root, ext = os.path.splitext(file_path)\n",
    "    split_file1 = root + '_split1' + ext\n",
    "    split_file2 = root + '_split2' + ext\n",
    "\n",
    "    os.rename(split_file1, file_dir / 'gghhh-4pT40_4b-train.h5')\n",
    "    os.rename(split_file2, file_dir / 'gghhh-4pT40_4b-test.h5')\n",
    "\n",
    "    output_file = file_dir / 'gghhh-4pT40_6b.h5'\n",
    "    six_b_file = select_nb_event(file_dir / 'gghhh-4pT40_4b-2.h5', output_file, nb=6)\n",
    "    print_triHiggs_h5_info(six_b_file)\n",
    "\n",
    "    size = 50000 // n_mass\n",
    "    utils.split_h5_size(six_b_file, size)\n",
    "\n",
    "    root, ext = os.path.splitext(six_b_file)\n",
    "    split_file1 = root + '_split1' + ext\n",
    "    split_file2 = root + '_split2' + ext\n",
    "\n",
    "    os.rename(split_file1, file_dir / 'gghhh-4pT40_6b-1.h5')\n",
    "    os.rename(split_file2, file_dir / 'gghhh-4pT40_6b-2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $4b$ dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'./Sample/SPANet/bkg/pp6b-4pT40_4b-train.h5' and ('./Sample/SPANet/sig/gghhh_bsm_570_250/gghhh-4pT40_4b-train.h5', './Sample/SPANet/sig/gghhh_bsm_600_325/gghhh-4pT40_4b-train.h5', './Sample/SPANet/sig/gghhh_bsm_700_325/gghhh-4pT40_4b-train.h5', './Sample/SPANet/sig/gghhh_bsm_800_325/gghhh-4pT40_4b-train.h5', './Sample/SPANet/sig/gghhh_bsm_700_400/gghhh-4pT40_4b-train.h5', './Sample/SPANet/sig/gghhh_bsm_800_400/gghhh-4pT40_4b-train.h5') are same structure, can be merged.\n",
      "./Sample/SPANet/bkg/pp6b-4pT40_4b-train_merged.h5 not exist. Copy ./Sample/SPANet/bkg/pp6b-4pT40_4b-train.h5 to ./Sample/SPANet/bkg/pp6b-4pT40_4b-train_merged.h5\n",
      "Size of ./Sample/SPANet/bkg/pp6b-4pT40_4b-train.h5: 900000\n",
      "Size of ./Sample/SPANet/sig/gghhh_bsm_570_250/gghhh-4pT40_4b-train.h5: 74999\n",
      "Size of ./Sample/SPANet/bkg/pp6b-4pT40_4b-train_merged.h5: 974999\n",
      "Size of ./Sample/SPANet/sig/gghhh_bsm_600_325/gghhh-4pT40_4b-train.h5: 74999\n",
      "Size of ./Sample/SPANet/bkg/pp6b-4pT40_4b-train_merged.h5: 1049998\n",
      "Size of ./Sample/SPANet/sig/gghhh_bsm_700_325/gghhh-4pT40_4b-train.h5: 74999\n",
      "Size of ./Sample/SPANet/bkg/pp6b-4pT40_4b-train_merged.h5: 1124997\n",
      "Size of ./Sample/SPANet/sig/gghhh_bsm_800_325/gghhh-4pT40_4b-train.h5: 74999\n",
      "Size of ./Sample/SPANet/bkg/pp6b-4pT40_4b-train_merged.h5: 1199996\n",
      "Size of ./Sample/SPANet/sig/gghhh_bsm_700_400/gghhh-4pT40_4b-train.h5: 74999\n",
      "Size of ./Sample/SPANet/bkg/pp6b-4pT40_4b-train_merged.h5: 1274995\n",
      "Size of ./Sample/SPANet/sig/gghhh_bsm_800_400/gghhh-4pT40_4b-train.h5: 74999\n",
      "Size of ./Sample/SPANet/bkg/pp6b-4pT40_4b-train_merged.h5: 1349994\n",
      "'./Sample/SPANet/bkg/pp6b-4pT40_4b-test.h5' and ('./Sample/SPANet/sig/gghhh_bsm_570_250/gghhh-4pT40_4b-test.h5', './Sample/SPANet/sig/gghhh_bsm_600_325/gghhh-4pT40_4b-test.h5', './Sample/SPANet/sig/gghhh_bsm_700_325/gghhh-4pT40_4b-test.h5', './Sample/SPANet/sig/gghhh_bsm_800_325/gghhh-4pT40_4b-test.h5', './Sample/SPANet/sig/gghhh_bsm_700_400/gghhh-4pT40_4b-test.h5', './Sample/SPANet/sig/gghhh_bsm_800_400/gghhh-4pT40_4b-test.h5') are same structure, can be merged.\n",
      "./Sample/SPANet/bkg/pp6b-4pT40_4b-test_merged.h5 exist. Can not copy ./Sample/SPANet/bkg/pp6b-4pT40_4b-test.h5 to ./Sample/SPANet/bkg/pp6b-4pT40_4b-test_merged.h5\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "rename: src should be string, bytes or os.PathLike, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[13], line 13\u001b[0m\n",
      "\u001b[1;32m     10\u001b[0m merged_h5 \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mmerge_h5_file(\u001b[38;5;241m*\u001b[39mfiles)\n",
      "\u001b[1;32m     12\u001b[0m new_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./Sample/SPANet/triHiggs-4pT40_4b-mix_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_mass\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-test.h5\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[0;32m---> 13\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrename\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmerged_h5\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_file\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "\u001b[0;31mTypeError\u001b[0m: rename: src should be string, bytes or os.PathLike, not NoneType"
     ]
    }
   ],
   "source": [
    "files = ['./Sample/SPANet/bkg/pp6b-4pT40_4b-train.h5'] + [f'./Sample/SPANet/sig/gghhh_bsm_{m3_m2}/gghhh-4pT40_4b-train.h5' for m3_m2 in m3_m2_list]\n",
    "# files = [f'./Sample/SPANet/sig/gghhh_bsm_{m3_m2}/gghhh-4pT40_4b-train.h5' for m3_m2 in m3_m2_list]\n",
    "# files = [f'./Sample/45b_400k/{m3_m2}_45b_400000.h5' for m3_m2 in m3_m2_list]\n",
    "merged_h5 = utils.merge_h5_file(*files)\n",
    "\n",
    "new_file = f'./Sample/SPANet/triHiggs-4pT40_4b-mix_{n_mass}-train.h5'\n",
    "os.rename(merged_h5, new_file)\n",
    "\n",
    "files = ['./Sample/SPANet/bkg/pp6b-4pT40_4b-test.h5'] + [f'./Sample/SPANet/sig/gghhh_bsm_{m3_m2}/gghhh-4pT40_4b-test.h5' for m3_m2 in m3_m2_list]\n",
    "merged_h5 = utils.merge_h5_file(*files)\n",
    "\n",
    "new_file = f'./Sample/SPANet/triHiggs-4pT40_4b-mix_{n_mass}-test.h5'\n",
    "os.rename(merged_h5, new_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 1349994\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[14], line 2\u001b[0m\n",
      "\u001b[1;32m      1\u001b[0m utils\u001b[38;5;241m.\u001b[39mshuffle_h5(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./Sample/SPANet/triHiggs-4pT40_4b-mix_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_mass\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-train.h5\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;32m----> 2\u001b[0m \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshuffle_h5\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./Sample/SPANet/triHiggs-4pT40_4b-mix_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mn_mass\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m-test.h5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[0;32m~/3h6b_collider_study/utils_HDF5.py:134\u001b[0m, in \u001b[0;36mshuffle_h5\u001b[0;34m(file_path)\u001b[0m\n",
      "\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m h5py\u001b[38;5;241m.\u001b[39mFile(file_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[1;32m    133\u001b[0m     dataset_keys \u001b[38;5;241m=\u001b[39m get_dataset_keys(f)\n",
      "\u001b[0;32m--> 134\u001b[0m     nevent \u001b[38;5;241m=\u001b[39m f[\u001b[43mdataset_keys\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;32m    135\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDataset size: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnevent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;32m    137\u001b[0m     ind_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(nevent))\n",
      "\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "utils.shuffle_h5(f'./Sample/SPANet/triHiggs-4pT40_4b-mix_{n_mass}-train.h5')\n",
    "utils.shuffle_h5(f'./Sample/SPANet/triHiggs-4pT40_4b-mix_{n_mass}-test.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $6b$ dataset: 50k + 50K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'./Sample/SPANet/bkg/pp6b-4pT40_6b-1.h5' and ('./Sample/SPANet/sig/gghhh_bsm_420_280/gghhh-4pT40_6b-1.h5', './Sample/SPANet/sig/gghhh_bsm_500_275/gghhh-4pT40_6b-1.h5', './Sample/SPANet/sig/gghhh_bsm_500_300/gghhh-4pT40_6b-1.h5', './Sample/SPANet/sig/gghhh_bsm_520_325/gghhh-4pT40_6b-1.h5', './Sample/SPANet/sig/gghhh_bsm_570_250/gghhh-4pT40_6b-1.h5', './Sample/SPANet/sig/gghhh_bsm_600_325/gghhh-4pT40_6b-1.h5', './Sample/SPANet/sig/gghhh_bsm_700_325/gghhh-4pT40_6b-1.h5', './Sample/SPANet/sig/gghhh_bsm_800_325/gghhh-4pT40_6b-1.h5', './Sample/SPANet/sig/gghhh_bsm_700_400/gghhh-4pT40_6b-1.h5', './Sample/SPANet/sig/gghhh_bsm_800_400/gghhh-4pT40_6b-1.h5') are same structure, can be merged.\n",
      "./Sample/SPANet/bkg/pp6b-4pT40_6b-1_merged.h5 not exist. Copy ./Sample/SPANet/bkg/pp6b-4pT40_6b-1.h5 to ./Sample/SPANet/bkg/pp6b-4pT40_6b-1_merged.h5\n",
      "Size of ./Sample/SPANet/bkg/pp6b-4pT40_6b-1.h5: 50000\n",
      "Size of ./Sample/SPANet/sig/gghhh_bsm_420_280/gghhh-4pT40_6b-1.h5: 5000\n",
      "Size of ./Sample/SPANet/bkg/pp6b-4pT40_6b-1_merged.h5: 55000\n",
      "Size of ./Sample/SPANet/sig/gghhh_bsm_500_275/gghhh-4pT40_6b-1.h5: 5000\n",
      "Size of ./Sample/SPANet/bkg/pp6b-4pT40_6b-1_merged.h5: 60000\n",
      "Size of ./Sample/SPANet/sig/gghhh_bsm_500_300/gghhh-4pT40_6b-1.h5: 5000\n",
      "Size of ./Sample/SPANet/bkg/pp6b-4pT40_6b-1_merged.h5: 65000\n",
      "Size of ./Sample/SPANet/sig/gghhh_bsm_520_325/gghhh-4pT40_6b-1.h5: 5000\n",
      "Size of ./Sample/SPANet/bkg/pp6b-4pT40_6b-1_merged.h5: 70000\n",
      "Size of ./Sample/SPANet/sig/gghhh_bsm_570_250/gghhh-4pT40_6b-1.h5: 5000\n",
      "Size of ./Sample/SPANet/bkg/pp6b-4pT40_6b-1_merged.h5: 75000\n",
      "Size of ./Sample/SPANet/sig/gghhh_bsm_600_325/gghhh-4pT40_6b-1.h5: 5000\n",
      "Size of ./Sample/SPANet/bkg/pp6b-4pT40_6b-1_merged.h5: 80000\n",
      "Size of ./Sample/SPANet/sig/gghhh_bsm_700_325/gghhh-4pT40_6b-1.h5: 5000\n",
      "Size of ./Sample/SPANet/bkg/pp6b-4pT40_6b-1_merged.h5: 85000\n",
      "Size of ./Sample/SPANet/sig/gghhh_bsm_800_325/gghhh-4pT40_6b-1.h5: 5000\n",
      "Size of ./Sample/SPANet/bkg/pp6b-4pT40_6b-1_merged.h5: 90000\n",
      "Size of ./Sample/SPANet/sig/gghhh_bsm_700_400/gghhh-4pT40_6b-1.h5: 5000\n",
      "Size of ./Sample/SPANet/bkg/pp6b-4pT40_6b-1_merged.h5: 95000\n",
      "Size of ./Sample/SPANet/sig/gghhh_bsm_800_400/gghhh-4pT40_6b-1.h5: 5000\n",
      "Size of ./Sample/SPANet/bkg/pp6b-4pT40_6b-1_merged.h5: 100000\n"
     ]
    }
   ],
   "source": [
    "files = ['./Sample/SPANet/bkg/pp6b-4pT40_6b-1.h5'] + [f'./Sample/SPANet/sig/gghhh_bsm_{m3_m2}/gghhh-4pT40_6b-1.h5' for m3_m2 in m3_m2_list]\n",
    "merged_h5 = utils.merge_h5_file(*files)\n",
    "\n",
    "new_file = './Sample/SPANet/triHiggs-4pT40_6b-mix_10.h5'\n",
    "os.rename(merged_h5, new_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRSM signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'./Sample/SPANet/TRSM/TRSM_420_280/gghhh-4pT40_4b-2.h5' and ('./Sample/SPANet/TRSM/TRSM_420_280/gghhh-4pT40_4b-test.h5', './Sample/SPANet/TRSM/TRSM_420_280/gghhh-4pT40_4b-03.h5', './Sample/SPANet/TRSM/TRSM_420_280/gghhh-4pT40_4b-train.h5', './Sample/SPANet/TRSM/TRSM_420_280/gghhh-4pT40_4b-1.h5', './Sample/SPANet/TRSM/TRSM_420_280/gghhh-4pT40_4b.h5') are same structure, can be merged.\n",
      "./Sample/SPANet/TRSM/TRSM_420_280/gghhh-4pT40_4b-2_merged.h5 not exist. Copy ./Sample/SPANet/TRSM/TRSM_420_280/gghhh-4pT40_4b-2.h5 to ./Sample/SPANet/TRSM/TRSM_420_280/gghhh-4pT40_4b-2_merged.h5\n",
      "Size of ./Sample/SPANet/TRSM/TRSM_420_280/gghhh-4pT40_4b-2.h5: 972639\n",
      "Size of ./Sample/SPANet/TRSM/TRSM_420_280/gghhh-4pT40_4b-test.h5: 25000\n",
      "Size of ./Sample/SPANet/TRSM/TRSM_420_280/gghhh-4pT40_4b-2_merged.h5: 997639\n",
      "Size of ./Sample/SPANet/TRSM/TRSM_420_280/gghhh-4pT40_4b-03.h5: 324213\n",
      "Size of ./Sample/SPANet/TRSM/TRSM_420_280/gghhh-4pT40_4b-2_merged.h5: 1321852\n",
      "Size of ./Sample/SPANet/TRSM/TRSM_420_280/gghhh-4pT40_4b-train.h5: 225000\n",
      "Size of ./Sample/SPANet/TRSM/TRSM_420_280/gghhh-4pT40_4b-2_merged.h5: 1546852\n",
      "Size of ./Sample/SPANet/TRSM/TRSM_420_280/gghhh-4pT40_4b-1.h5: 250000\n",
      "Size of ./Sample/SPANet/TRSM/TRSM_420_280/gghhh-4pT40_4b-2_merged.h5: 1796852\n",
      "Size of ./Sample/SPANet/TRSM/TRSM_420_280/gghhh-4pT40_4b.h5: 1222639\n",
      "Size of ./Sample/SPANet/TRSM/TRSM_420_280/gghhh-4pT40_4b-2_merged.h5: 3019491\n",
      "'./Sample/SPANet/TRSM/TRSM_500_275/gghhh-4pT40_4b-2.h5' and ('./Sample/SPANet/TRSM/TRSM_500_275/gghhh-4pT40_4b-test.h5', './Sample/SPANet/TRSM/TRSM_500_275/gghhh-4pT40_4b-03.h5', './Sample/SPANet/TRSM/TRSM_500_275/gghhh-4pT40_4b-train.h5', './Sample/SPANet/TRSM/TRSM_500_275/gghhh-4pT40_4b-1.h5', './Sample/SPANet/TRSM/TRSM_500_275/gghhh-4pT40_4b-02.h5', './Sample/SPANet/TRSM/TRSM_500_275/gghhh-4pT40_4b.h5') are same structure, can be merged.\n",
      "./Sample/SPANet/TRSM/TRSM_500_275/gghhh-4pT40_4b-2_merged.h5 not exist. Copy ./Sample/SPANet/TRSM/TRSM_500_275/gghhh-4pT40_4b-2.h5 to ./Sample/SPANet/TRSM/TRSM_500_275/gghhh-4pT40_4b-2_merged.h5\n",
      "Size of ./Sample/SPANet/TRSM/TRSM_500_275/gghhh-4pT40_4b-2.h5: 1296189\n",
      "Size of ./Sample/SPANet/TRSM/TRSM_500_275/gghhh-4pT40_4b-test.h5: 25000\n",
      "Size of ./Sample/SPANet/TRSM/TRSM_500_275/gghhh-4pT40_4b-2_merged.h5: 1321189\n",
      "Size of ./Sample/SPANet/TRSM/TRSM_500_275/gghhh-4pT40_4b-03.h5: 392931\n",
      "Size of ./Sample/SPANet/TRSM/TRSM_500_275/gghhh-4pT40_4b-2_merged.h5: 1714120\n",
      "Size of ./Sample/SPANet/TRSM/TRSM_500_275/gghhh-4pT40_4b-train.h5: 225000\n",
      "Size of ./Sample/SPANet/TRSM/TRSM_500_275/gghhh-4pT40_4b-2_merged.h5: 1939120\n",
      "Size of ./Sample/SPANet/TRSM/TRSM_500_275/gghhh-4pT40_4b-1.h5: 250000\n",
      "Size of ./Sample/SPANet/TRSM/TRSM_500_275/gghhh-4pT40_4b-2_merged.h5: 2189120\n",
      "Size of ./Sample/SPANet/TRSM/TRSM_500_275/gghhh-4pT40_4b-02.h5: 39132\n",
      "Size of ./Sample/SPANet/TRSM/TRSM_500_275/gghhh-4pT40_4b-2_merged.h5: 2228252\n",
      "Size of ./Sample/SPANet/TRSM/TRSM_500_275/gghhh-4pT40_4b.h5: 1546189\n",
      "Size of ./Sample/SPANet/TRSM/TRSM_500_275/gghhh-4pT40_4b-2_merged.h5: 3774441\n",
      "'./Sample/SPANet/TRSM/TRSM_500_300/gghhh-4pT40_4b-2.h5' and ('./Sample/SPANet/TRSM/TRSM_500_300/gghhh-4pT40_4b-test.h5', './Sample/SPANet/TRSM/TRSM_500_300/gghhh-4pT40_4b-03.h5', './Sample/SPANet/TRSM/TRSM_500_300/gghhh-4pT40_4b-train.h5', './Sample/SPANet/TRSM/TRSM_500_300/gghhh-4pT40_4b-1.h5', './Sample/SPANet/TRSM/TRSM_500_300/gghhh-4pT40_4b-02.h5', './Sample/SPANet/TRSM/TRSM_500_300/gghhh-4pT40_4b.h5') are same structure, can be merged.\n",
      "./Sample/SPANet/TRSM/TRSM_500_300/gghhh-4pT40_4b-2_merged.h5 not exist. Copy ./Sample/SPANet/TRSM/TRSM_500_300/gghhh-4pT40_4b-2.h5 to ./Sample/SPANet/TRSM/TRSM_500_300/gghhh-4pT40_4b-2_merged.h5\n",
      "Size of ./Sample/SPANet/TRSM/TRSM_500_300/gghhh-4pT40_4b-2.h5: 1315329\n",
      "Size of ./Sample/SPANet/TRSM/TRSM_500_300/gghhh-4pT40_4b-test.h5: 25000\n",
      "Size of ./Sample/SPANet/TRSM/TRSM_500_300/gghhh-4pT40_4b-2_merged.h5: 1340329\n",
      "Size of ./Sample/SPANet/TRSM/TRSM_500_300/gghhh-4pT40_4b-03.h5: 398362\n",
      "Size of ./Sample/SPANet/TRSM/TRSM_500_300/gghhh-4pT40_4b-2_merged.h5: 1738691\n",
      "Size of ./Sample/SPANet/TRSM/TRSM_500_300/gghhh-4pT40_4b-train.h5: 225000\n",
      "Size of ./Sample/SPANet/TRSM/TRSM_500_300/gghhh-4pT40_4b-2_merged.h5: 1963691\n",
      "Size of ./Sample/SPANet/TRSM/TRSM_500_300/gghhh-4pT40_4b-1.h5: 250000\n",
      "Size of ./Sample/SPANet/TRSM/TRSM_500_300/gghhh-4pT40_4b-2_merged.h5: 2213691\n",
      "Size of ./Sample/SPANet/TRSM/TRSM_500_300/gghhh-4pT40_4b-02.h5: 40081\n",
      "Size of ./Sample/SPANet/TRSM/TRSM_500_300/gghhh-4pT40_4b-2_merged.h5: 2253772\n",
      "Size of ./Sample/SPANet/TRSM/TRSM_500_300/gghhh-4pT40_4b.h5: 1565329\n",
      "Size of ./Sample/SPANet/TRSM/TRSM_500_300/gghhh-4pT40_4b-2_merged.h5: 3819101\n",
      "'./Sample/SPANet/TRSM/TRSM_520_325/gghhh-4pT40_4b-2.h5' and ('./Sample/SPANet/TRSM/TRSM_520_325/gghhh-4pT40_4b-test.h5', './Sample/SPANet/TRSM/TRSM_520_325/gghhh-4pT40_4b-03.h5', './Sample/SPANet/TRSM/TRSM_520_325/gghhh-4pT40_4b-train.h5', './Sample/SPANet/TRSM/TRSM_520_325/gghhh-4pT40_4b-1.h5', './Sample/SPANet/TRSM/TRSM_520_325/gghhh-4pT40_4b-02.h5', './Sample/SPANet/TRSM/TRSM_520_325/gghhh-4pT40_4b.h5') are same structure, can be merged.\n",
      "./Sample/SPANet/TRSM/TRSM_520_325/gghhh-4pT40_4b-2_merged.h5 not exist. Copy ./Sample/SPANet/TRSM/TRSM_520_325/gghhh-4pT40_4b-2.h5 to ./Sample/SPANet/TRSM/TRSM_520_325/gghhh-4pT40_4b-2_merged.h5\n",
      "Size of ./Sample/SPANet/TRSM/TRSM_520_325/gghhh-4pT40_4b-2.h5: 1375152\n",
      "Size of ./Sample/SPANet/TRSM/TRSM_520_325/gghhh-4pT40_4b-test.h5: 25000\n",
      "Size of ./Sample/SPANet/TRSM/TRSM_520_325/gghhh-4pT40_4b-2_merged.h5: 1400152\n",
      "Size of ./Sample/SPANet/TRSM/TRSM_520_325/gghhh-4pT40_4b-03.h5: 416527\n",
      "Size of ./Sample/SPANet/TRSM/TRSM_520_325/gghhh-4pT40_4b-2_merged.h5: 1816679\n",
      "Size of ./Sample/SPANet/TRSM/TRSM_520_325/gghhh-4pT40_4b-train.h5: 225000\n",
      "Size of ./Sample/SPANet/TRSM/TRSM_520_325/gghhh-4pT40_4b-2_merged.h5: 2041679\n",
      "Size of ./Sample/SPANet/TRSM/TRSM_520_325/gghhh-4pT40_4b-1.h5: 250000\n",
      "Size of ./Sample/SPANet/TRSM/TRSM_520_325/gghhh-4pT40_4b-2_merged.h5: 2291679\n",
      "Size of ./Sample/SPANet/TRSM/TRSM_520_325/gghhh-4pT40_4b-02.h5: 41857\n",
      "Size of ./Sample/SPANet/TRSM/TRSM_520_325/gghhh-4pT40_4b-2_merged.h5: 2333536\n",
      "Size of ./Sample/SPANet/TRSM/TRSM_520_325/gghhh-4pT40_4b.h5: 1625152\n",
      "Size of ./Sample/SPANet/TRSM/TRSM_520_325/gghhh-4pT40_4b-2_merged.h5: 3958688\n"
     ]
    }
   ],
   "source": [
    "m3_m2_list = [(420, 280), (500, 275), (500, 300), (520, 325)]\n",
    "for m3, m2 in m3_m2_list:\n",
    "    files_path = f'./Sample/SPANet/TRSM/TRSM_{m3}_{m2}/'\n",
    "    files = [os.path.join(files_path, name) for name in os.listdir(files_path) if name.startswith('gghhh-4pT40_4b')]\n",
    "    merged_h5 = utils.merge_h5_file(*files)\n",
    "\n",
    "    new_file = f'./Sample/SPANet/TRSM/TRSM_{m3}_{m2}/gghhh-4pT40_4b.h5'\n",
    "    os.rename(merged_h5, new_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of Sample/SPANet/TRSM/TRSM_420_280/gghhh-4pT40_4b.h5: 3019491\n",
      "Size of Sample/SPANet/TRSM/TRSM_420_280/gghhh-4pT40_4b_split1.h5: 250000\n",
      "Size of Sample/SPANet/TRSM/TRSM_420_280/gghhh-4pT40_4b_split2.h5: 2769491\n",
      "Size of Sample/SPANet/TRSM/TRSM_420_280/gghhh-4pT40_4b-1.h5: 250000\n",
      "Size of Sample/SPANet/TRSM/TRSM_420_280/gghhh-4pT40_4b-1_split1.h5: 225000\n",
      "Size of Sample/SPANet/TRSM/TRSM_420_280/gghhh-4pT40_4b-1_split2.h5: 25000\n",
      "Number of 6 b events: 347113\n",
      "Sample/SPANet/TRSM/TRSM_420_280/gghhh-4pT40_6b.h5\n",
      "Dataset size: 347113\n",
      "Number of 0 Higgs events: 4568\n",
      "Number of 1 Higgs events: 37083\n",
      "Number of 2 Higgs events: 69957\n",
      "Number of 3 Higgs events: 235505\n",
      "\\item Total sample size: 347,113\n",
      "\\item 1h sample size: 37,083\n",
      "\\item 2h sample size: 69,957\n",
      "\\item 3h sample size: 235,505\n",
      "Size of Sample/SPANet/TRSM/TRSM_420_280/gghhh-4pT40_6b.h5: 347113\n",
      "Size of Sample/SPANet/TRSM/TRSM_420_280/gghhh-4pT40_6b_split1.h5: 12500\n",
      "Size of Sample/SPANet/TRSM/TRSM_420_280/gghhh-4pT40_6b_split2.h5: 334613\n",
      "Size of Sample/SPANet/TRSM/TRSM_500_275/gghhh-4pT40_4b.h5: 3774441\n",
      "Size of Sample/SPANet/TRSM/TRSM_500_275/gghhh-4pT40_4b_split1.h5: 250000\n",
      "Size of Sample/SPANet/TRSM/TRSM_500_275/gghhh-4pT40_4b_split2.h5: 3524441\n",
      "Size of Sample/SPANet/TRSM/TRSM_500_275/gghhh-4pT40_4b-1.h5: 250000\n",
      "Size of Sample/SPANet/TRSM/TRSM_500_275/gghhh-4pT40_4b-1_split1.h5: 225000\n",
      "Size of Sample/SPANet/TRSM/TRSM_500_275/gghhh-4pT40_4b-1_split2.h5: 25000\n",
      "Number of 6 b events: 462812\n",
      "Sample/SPANet/TRSM/TRSM_500_275/gghhh-4pT40_6b.h5\n",
      "Dataset size: 462812\n",
      "Number of 0 Higgs events: 4758\n",
      "Number of 1 Higgs events: 46885\n",
      "Number of 2 Higgs events: 98764\n",
      "Number of 3 Higgs events: 312405\n",
      "\\item Total sample size: 462,812\n",
      "\\item 1h sample size: 46,885\n",
      "\\item 2h sample size: 98,764\n",
      "\\item 3h sample size: 312,405\n",
      "Size of Sample/SPANet/TRSM/TRSM_500_275/gghhh-4pT40_6b.h5: 462812\n",
      "Size of Sample/SPANet/TRSM/TRSM_500_275/gghhh-4pT40_6b_split1.h5: 12500\n",
      "Size of Sample/SPANet/TRSM/TRSM_500_275/gghhh-4pT40_6b_split2.h5: 450312\n",
      "Size of Sample/SPANet/TRSM/TRSM_500_300/gghhh-4pT40_4b.h5: 3819101\n",
      "Size of Sample/SPANet/TRSM/TRSM_500_300/gghhh-4pT40_4b_split1.h5: 250000\n",
      "Size of Sample/SPANet/TRSM/TRSM_500_300/gghhh-4pT40_4b_split2.h5: 3569101\n",
      "Size of Sample/SPANet/TRSM/TRSM_500_300/gghhh-4pT40_4b-1.h5: 250000\n",
      "Size of Sample/SPANet/TRSM/TRSM_500_300/gghhh-4pT40_4b-1_split1.h5: 225000\n",
      "Size of Sample/SPANet/TRSM/TRSM_500_300/gghhh-4pT40_4b-1_split2.h5: 25000\n",
      "Number of 6 b events: 463768\n",
      "Sample/SPANet/TRSM/TRSM_500_300/gghhh-4pT40_6b.h5\n",
      "Dataset size: 463768\n",
      "Number of 0 Higgs events: 5092\n",
      "Number of 1 Higgs events: 45637\n",
      "Number of 2 Higgs events: 101252\n",
      "Number of 3 Higgs events: 311787\n",
      "\\item Total sample size: 463,768\n",
      "\\item 1h sample size: 45,637\n",
      "\\item 2h sample size: 101,252\n",
      "\\item 3h sample size: 311,787\n",
      "Size of Sample/SPANet/TRSM/TRSM_500_300/gghhh-4pT40_6b.h5: 463768\n",
      "Size of Sample/SPANet/TRSM/TRSM_500_300/gghhh-4pT40_6b_split1.h5: 12500\n",
      "Size of Sample/SPANet/TRSM/TRSM_500_300/gghhh-4pT40_6b_split2.h5: 451268\n",
      "Size of Sample/SPANet/TRSM/TRSM_520_325/gghhh-4pT40_4b.h5: 3958688\n",
      "Size of Sample/SPANet/TRSM/TRSM_520_325/gghhh-4pT40_4b_split1.h5: 250000\n",
      "Size of Sample/SPANet/TRSM/TRSM_520_325/gghhh-4pT40_4b_split2.h5: 3708688\n",
      "Size of Sample/SPANet/TRSM/TRSM_520_325/gghhh-4pT40_4b-1.h5: 250000\n",
      "Size of Sample/SPANet/TRSM/TRSM_520_325/gghhh-4pT40_4b-1_split1.h5: 225000\n",
      "Size of Sample/SPANet/TRSM/TRSM_520_325/gghhh-4pT40_4b-1_split2.h5: 25000\n",
      "Number of 6 b events: 493238\n",
      "Sample/SPANet/TRSM/TRSM_520_325/gghhh-4pT40_6b.h5\n",
      "Dataset size: 493238\n",
      "Number of 0 Higgs events: 4800\n",
      "Number of 1 Higgs events: 46378\n",
      "Number of 2 Higgs events: 109388\n",
      "Number of 3 Higgs events: 332672\n",
      "\\item Total sample size: 493,238\n",
      "\\item 1h sample size: 46,378\n",
      "\\item 2h sample size: 109,388\n",
      "\\item 3h sample size: 332,672\n",
      "Size of Sample/SPANet/TRSM/TRSM_520_325/gghhh-4pT40_6b.h5: 493238\n",
      "Size of Sample/SPANet/TRSM/TRSM_520_325/gghhh-4pT40_6b_split1.h5: 12500\n",
      "Size of Sample/SPANet/TRSM/TRSM_520_325/gghhh-4pT40_6b_split2.h5: 480738\n"
     ]
    }
   ],
   "source": [
    "n_mass = len(m3_m2_list)\n",
    "n_4b_total = 1000000\n",
    "for m3, m2 in m3_m2_list:\n",
    "\n",
    "    # split signal files for 4b and 6b\n",
    "    file_dir = Path(f'./Sample/SPANet/TRSM/TRSM_{m3}_{m2}/')\n",
    "    file_path = file_dir / 'gghhh-4pT40_4b.h5'\n",
    "    size = n_4b_total // n_mass\n",
    "    utils.split_h5_size(file_path, size)\n",
    "\n",
    "    root, ext = os.path.splitext(file_path)\n",
    "    split_file1 = root + '_split1' + ext\n",
    "    split_file2 = root + '_split2' + ext\n",
    "\n",
    "    os.rename(split_file1, file_dir / 'gghhh-4pT40_4b-1.h5')\n",
    "    os.rename(split_file2, file_dir / 'gghhh-4pT40_4b-2.h5')\n",
    "\n",
    "    file_path = file_dir / 'gghhh-4pT40_4b-1.h5'\n",
    "    size = int(n_4b_total // n_mass * 0.9)\n",
    "    utils.split_h5_size(file_path, size)\n",
    "\n",
    "    root, ext = os.path.splitext(file_path)\n",
    "    split_file1 = root + '_split1' + ext\n",
    "    split_file2 = root + '_split2' + ext\n",
    "\n",
    "    os.rename(split_file1, file_dir / 'gghhh-4pT40_4b-train.h5')\n",
    "    os.rename(split_file2, file_dir / 'gghhh-4pT40_4b-test.h5')\n",
    "\n",
    "    output_file = file_dir / 'gghhh-4pT40_6b.h5'\n",
    "    six_b_file = select_nb_event(file_dir / 'gghhh-4pT40_4b-2.h5', output_file, nb=6)\n",
    "    print_triHiggs_h5_info(six_b_file)\n",
    "\n",
    "    size = 50000 // n_mass\n",
    "    utils.split_h5_size(six_b_file, size)\n",
    "\n",
    "    root, ext = os.path.splitext(six_b_file)\n",
    "    split_file1 = root + '_split1' + ext\n",
    "    split_file2 = root + '_split2' + ext\n",
    "\n",
    "    os.rename(split_file1, file_dir / 'gghhh-4pT40_6b-1.h5')\n",
    "    os.rename(split_file2, file_dir / 'gghhh-4pT40_6b-2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $4b$ dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'./Sample/SPANet/bkg/pp6b-4pT40_4b-train.h5' and ('./Sample/SPANet/TRSM/TRSM_420_280/gghhh-4pT40_4b-train.h5', './Sample/SPANet/TRSM/TRSM_500_275/gghhh-4pT40_4b-train.h5', './Sample/SPANet/TRSM/TRSM_500_300/gghhh-4pT40_4b-train.h5', './Sample/SPANet/TRSM/TRSM_520_325/gghhh-4pT40_4b-train.h5') are same structure, can be merged.\n",
      "./Sample/SPANet/bkg/pp6b-4pT40_4b-train_merged.h5 not exist. Copy ./Sample/SPANet/bkg/pp6b-4pT40_4b-train.h5 to ./Sample/SPANet/bkg/pp6b-4pT40_4b-train_merged.h5\n",
      "Size of ./Sample/SPANet/bkg/pp6b-4pT40_4b-train.h5: 900000\n",
      "Size of ./Sample/SPANet/TRSM/TRSM_420_280/gghhh-4pT40_4b-train.h5: 225000\n",
      "Size of ./Sample/SPANet/bkg/pp6b-4pT40_4b-train_merged.h5: 1125000\n",
      "Size of ./Sample/SPANet/TRSM/TRSM_500_275/gghhh-4pT40_4b-train.h5: 225000\n",
      "Size of ./Sample/SPANet/bkg/pp6b-4pT40_4b-train_merged.h5: 1350000\n",
      "Size of ./Sample/SPANet/TRSM/TRSM_500_300/gghhh-4pT40_4b-train.h5: 225000\n",
      "Size of ./Sample/SPANet/bkg/pp6b-4pT40_4b-train_merged.h5: 1575000\n",
      "Size of ./Sample/SPANet/TRSM/TRSM_520_325/gghhh-4pT40_4b-train.h5: 225000\n",
      "Size of ./Sample/SPANet/bkg/pp6b-4pT40_4b-train_merged.h5: 1800000\n",
      "'./Sample/SPANet/bkg/pp6b-4pT40_4b-test.h5' and ('./Sample/SPANet/TRSM/TRSM_520_325/gghhh-4pT40_4b-test.h5', './Sample/SPANet/TRSM/TRSM_520_325/gghhh-4pT40_4b-test.h5', './Sample/SPANet/TRSM/TRSM_520_325/gghhh-4pT40_4b-test.h5', './Sample/SPANet/TRSM/TRSM_520_325/gghhh-4pT40_4b-test.h5') are same structure, can be merged.\n",
      "./Sample/SPANet/bkg/pp6b-4pT40_4b-test_merged.h5 not exist. Copy ./Sample/SPANet/bkg/pp6b-4pT40_4b-test.h5 to ./Sample/SPANet/bkg/pp6b-4pT40_4b-test_merged.h5\n",
      "Size of ./Sample/SPANet/bkg/pp6b-4pT40_4b-test.h5: 100000\n",
      "Size of ./Sample/SPANet/TRSM/TRSM_520_325/gghhh-4pT40_4b-test.h5: 25000\n",
      "Size of ./Sample/SPANet/bkg/pp6b-4pT40_4b-test_merged.h5: 125000\n",
      "Size of ./Sample/SPANet/TRSM/TRSM_520_325/gghhh-4pT40_4b-test.h5: 25000\n",
      "Size of ./Sample/SPANet/bkg/pp6b-4pT40_4b-test_merged.h5: 150000\n",
      "Size of ./Sample/SPANet/TRSM/TRSM_520_325/gghhh-4pT40_4b-test.h5: 25000\n",
      "Size of ./Sample/SPANet/bkg/pp6b-4pT40_4b-test_merged.h5: 175000\n",
      "Size of ./Sample/SPANet/TRSM/TRSM_520_325/gghhh-4pT40_4b-test.h5: 25000\n",
      "Size of ./Sample/SPANet/bkg/pp6b-4pT40_4b-test_merged.h5: 200000\n"
     ]
    }
   ],
   "source": [
    "files = ['./Sample/SPANet/bkg/pp6b-4pT40_4b-train.h5'] + [f'./Sample/SPANet/TRSM/TRSM_{m3}_{m2}/gghhh-4pT40_4b-train.h5' for m3, m2 in m3_m2_list]\n",
    "merged_h5 = utils.merge_h5_file(*files)\n",
    "\n",
    "train_file = f'./Sample/SPANet/triHiggs_TRSM-4pT40_4b-mix_{n_mass}-train.h5'\n",
    "os.rename(merged_h5, train_file)\n",
    "\n",
    "files = ['./Sample/SPANet/bkg/pp6b-4pT40_4b-test.h5'] + [f'./Sample/SPANet/TRSM/TRSM_{m3}_{m2}/gghhh-4pT40_4b-test.h5' for m3_m2 in m3_m2_list]\n",
    "merged_h5 = utils.merge_h5_file(*files)\n",
    "\n",
    "test_file = f'./Sample/SPANet/triHiggs_TRSM-4pT40_4b-mix_{n_mass}-test.h5'\n",
    "os.rename(merged_h5, test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 1800000\n",
      "Dataset size: 200000\n"
     ]
    }
   ],
   "source": [
    "utils.shuffle_h5(train_file)\n",
    "utils.shuffle_h5(test_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $6b$ dataset: 50k + 50K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'./Sample/SPANet/bkg/pp6b-4pT40_6b-1.h5' and ('./Sample/SPANet/TRSM/TRSM_420_280/gghhh-4pT40_6b-1.h5', './Sample/SPANet/TRSM/TRSM_500_275/gghhh-4pT40_6b-1.h5', './Sample/SPANet/TRSM/TRSM_500_300/gghhh-4pT40_6b-1.h5', './Sample/SPANet/TRSM/TRSM_520_325/gghhh-4pT40_6b-1.h5') are same structure, can be merged.\n",
      "./Sample/SPANet/bkg/pp6b-4pT40_6b-1_merged.h5 not exist. Copy ./Sample/SPANet/bkg/pp6b-4pT40_6b-1.h5 to ./Sample/SPANet/bkg/pp6b-4pT40_6b-1_merged.h5\n",
      "Size of ./Sample/SPANet/bkg/pp6b-4pT40_6b-1.h5: 50000\n",
      "Size of ./Sample/SPANet/TRSM/TRSM_420_280/gghhh-4pT40_6b-1.h5: 12500\n",
      "Size of ./Sample/SPANet/bkg/pp6b-4pT40_6b-1_merged.h5: 62500\n",
      "Size of ./Sample/SPANet/TRSM/TRSM_500_275/gghhh-4pT40_6b-1.h5: 12500\n",
      "Size of ./Sample/SPANet/bkg/pp6b-4pT40_6b-1_merged.h5: 75000\n",
      "Size of ./Sample/SPANet/TRSM/TRSM_500_300/gghhh-4pT40_6b-1.h5: 12500\n",
      "Size of ./Sample/SPANet/bkg/pp6b-4pT40_6b-1_merged.h5: 87500\n",
      "Size of ./Sample/SPANet/TRSM/TRSM_520_325/gghhh-4pT40_6b-1.h5: 12500\n",
      "Size of ./Sample/SPANet/bkg/pp6b-4pT40_6b-1_merged.h5: 100000\n"
     ]
    }
   ],
   "source": [
    "files = ['./Sample/SPANet/bkg/pp6b-4pT40_6b-1.h5'] + [f'./Sample/SPANet/TRSM/TRSM_{m3}_{m2}/gghhh-4pT40_6b-1.h5' for m3, m2 in m3_m2_list]\n",
    "merged_h5 = utils.merge_h5_file(*files)\n",
    "\n",
    "new_file = f'./Sample/SPANet/triHiggs_TRSM-4pT40_6b-mix_{n_mass}.h5'\n",
    "os.rename(merged_h5, new_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process SPANet predict file for pairing and DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_labels(file_path, label_path):\n",
    "    with h5py.File(label_path, 'r') as f:\n",
    "        label = f['CLASSIFICATIONS/EVENT/signal'][...]\n",
    "\n",
    "    with h5py.File(file_path, 'r+') as f:\n",
    "        if 'CLASSIFICATIONS/EVENT/signal' in f:\n",
    "            del f['CLASSIFICATIONS/EVENT/signal']\n",
    "        f.create_dataset('CLASSIFICATIONS/EVENT/signal', data=label, chunks=True, maxshape=(None,))\n",
    "\n",
    "def rename_dataset(file_path):\n",
    "    with h5py.File(file_path, 'r+') as f:\n",
    "        for key in utils.get_dataset_keys(f):\n",
    "            if key.startswith('SpecialKey.'):\n",
    "                new_key = key.replace('SpecialKey.', '')\n",
    "            else:\n",
    "                new_key = key\n",
    "            # first word capitalize\n",
    "            new_key = new_key.split('/')\n",
    "            new_key = '/'.join([new_key[0].upper()] + new_key[1:])\n",
    "            if new_key == key:\n",
    "                continue\n",
    "            \n",
    "            maxShape = list(f[key].maxshape)\n",
    "            maxShape[0] = None\n",
    "            f.create_dataset(new_key, data=f[key][...], chunks=True, maxshape=maxShape)\n",
    "            del f[key]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_dataset('Sample/SPANet/triHiggs-4pT40_4b-mix-train-4b_SPANet_pairing.h5')\n",
    "rename_dataset('Sample/SPANet/triHiggs-4pT40_4b-mix-test-4b_SPANet_pairing.h5')\n",
    "\n",
    "file_path = 'Sample/SPANet/triHiggs-4pT40_4b-mix-train-4b_SPANet_pairing.h5'\n",
    "label_path = 'Sample/SPANet/triHiggs-4pT40_4b-mix-train.h5'\n",
    "replace_labels(file_path, label_path)\n",
    "\n",
    "file_path = 'Sample/SPANet/triHiggs-4pT40_4b-mix-test-4b_SPANet_pairing.h5'\n",
    "label_path = 'Sample/SPANet/triHiggs-4pT40_4b-mix-test.h5'\n",
    "replace_labels(file_path, label_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m3_m2 in ['420_280', '500_275', '500_300', '520_325']:\n",
    "    rename_dataset(f'Sample/SPANet/sig/gghhh_bsm_{m3_m2}/gghhh-4pT40_4b-test-4b_SPANet_pairing.h5')\n",
    "    rename_dataset(f'Sample/SPANet/sig/gghhh_bsm_{m3_m2}/gghhh-4pT40_6b-1-4b_SPANet_pairing.h5')\n",
    "\n",
    "    file_path = f'Sample/SPANet/sig/gghhh_bsm_{m3_m2}/gghhh-4pT40_4b-test-4b_SPANet_pairing.h5'\n",
    "    label_path = f'Sample/SPANet/sig/gghhh_bsm_{m3_m2}/gghhh-4pT40_4b-test.h5'\n",
    "    replace_labels(file_path, label_path)\n",
    "\n",
    "    file_path = f'Sample/SPANet/sig/gghhh_bsm_{m3_m2}/gghhh-4pT40_6b-1-4b_SPANet_pairing.h5'\n",
    "    label_path = f'Sample/SPANet/sig/gghhh_bsm_{m3_m2}/gghhh-4pT40_6b-1.h5'\n",
    "    replace_labels(file_path, label_path)\n",
    "\n",
    "rename_dataset('./Sample/SPANet/bkg/pp6b-4pT40_4b-test-4b_SPANet_pairing.h5')\n",
    "rename_dataset('./Sample/SPANet/bkg/pp6b-4pT40_6b-1-4b_SPANet_pairing.h5')\n",
    "\n",
    "file_path = './Sample/SPANet/bkg/pp6b-4pT40_4b-test-4b_SPANet_pairing.h5'\n",
    "label_path = './Sample/SPANet/bkg/pp6b-4pT40_4b-test.h5'\n",
    "replace_labels(file_path, label_path)\n",
    "\n",
    "file_path = './Sample/SPANet/bkg/pp6b-4pT40_6b-1-4b_SPANet_pairing.h5'\n",
    "label_path = './Sample/SPANet/bkg/pp6b-4pT40_6b-1.h5'\n",
    "replace_labels(file_path, label_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_dataset('Sample/SPANet/triHiggs-4pT40_6b-mix-4b_SPANet_pairing.h5')\n",
    "\n",
    "file_path = 'Sample/SPANet/triHiggs-4pT40_6b-mix-4b_SPANet_pairing.h5'\n",
    "label_path = 'Sample/SPANet/triHiggs-4pT40_6b-mix.h5'\n",
    "replace_labels(file_path, label_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate 6b event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./Sample/SPANet/pp6b_0b.h5\n",
      "Dataset size: 1000000\n",
      "Number of 0 Higgs events: 1000000\n",
      "Number of 1 Higgs events: 0\n",
      "Number of 2 Higgs events: 0\n",
      "Number of 3 Higgs events: 0\n",
      "\\item Total sample size: 1,000,000\n",
      "\\item 1h sample size: 0\n",
      "\\item 2h sample size: 0\n",
      "\\item 3h sample size: 0\n",
      "Number of 6 b events: 28755\n",
      "./Sample/SPANet/pp6b_6b.h5\n",
      "Dataset size: 28755\n",
      "Number of 0 Higgs events: 28755\n",
      "Number of 1 Higgs events: 0\n",
      "Number of 2 Higgs events: 0\n",
      "Number of 3 Higgs events: 0\n",
      "\\item Total sample size: 28,755\n",
      "\\item 1h sample size: 0\n",
      "\\item 2h sample size: 0\n",
      "\\item 3h sample size: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'total': 28755, '0h': 28755, '1h': 0, '2h': 0, '3h': 0}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = './Sample/SPANet/pp6b_0b.h5'\n",
    "print_triHiggs_h5_info(file_path)\n",
    "\n",
    "output_file = './Sample/SPANet/pp6b_6b.h5'\n",
    "six_b_file = select_6b_event(file_path, output_file)\n",
    "print_triHiggs_h5_info(six_b_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'./Sample/SPANet/pp6b_0b.h5' and ('./Sample/SPANet/pp6b_0b_2.h5',) are same structure, can be merged.\n",
      "./Sample/SPANet/pp6b_0b_merged.h5 not exist. Copy ./Sample/SPANet/pp6b_0b.h5 to ./Sample/SPANet/pp6b_0b_merged.h5\n",
      "Size of ./Sample/SPANet/pp6b_0b.h5: 1000000\n",
      "Size of ./Sample/SPANet/pp6b_0b_2.h5: 808254\n",
      "Size of ./Sample/SPANet/pp6b_0b_merged.h5: 1808254\n",
      "./Sample/SPANet/pp6b_0b_merged.h5\n",
      "Dataset size: 1808254\n",
      "Number of 0 Higgs events: 1808254\n",
      "Number of 1 Higgs events: 0\n",
      "Number of 2 Higgs events: 0\n",
      "Number of 3 Higgs events: 0\n",
      "\\item Total sample size: 1,808,254\n",
      "\\item 1h sample size: 0\n",
      "\\item 2h sample size: 0\n",
      "\\item 3h sample size: 0\n",
      "Number of 4 b events: 790372\n",
      "./Sample/SPANet/pp6b_4b.h5\n",
      "Dataset size: 790372\n",
      "Number of 0 Higgs events: 790372\n",
      "Number of 1 Higgs events: 0\n",
      "Number of 2 Higgs events: 0\n",
      "Number of 3 Higgs events: 0\n",
      "\\item Total sample size: 790,372\n",
      "\\item 1h sample size: 0\n",
      "\\item 2h sample size: 0\n",
      "\\item 3h sample size: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'total': 790372, '0h': 790372, '1h': 0, '2h': 0, '3h': 0}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = ['./Sample/SPANet/pp6b_0b.h5', './Sample/SPANet/pp6b_0b_2.h5']\n",
    "file_path = utils.merge_h5_file(*files)\n",
    "print_triHiggs_h5_info(file_path)\n",
    "\n",
    "output_file = './Sample/SPANet/pp6b_4b.h5'\n",
    "nb_file = select_nb_event(file_path, output_file, nb=4)\n",
    "print_triHiggs_h5_info(nb_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../SPANet2/data/triHiggs/triHiggs_0b_3h_test.h5\n",
      "Dataset size: 200000\n",
      "Number of 0 Higgs events: 100000\n",
      "Number of 1 Higgs events: 0\n",
      "Number of 2 Higgs events: 0\n",
      "Number of 3 Higgs events: 100000\n",
      "\\item Total sample size: 200,000\n",
      "\\item 1h sample size: 0\n",
      "\\item 2h sample size: 0\n",
      "\\item 3h sample size: 100,000\n",
      "Number of 6 b events: 11521\n",
      "../SPANet2/data/triHiggs/triHiggs_6b_3h_test.h5\n",
      "Dataset size: 11521\n",
      "Number of 0 Higgs events: 2905\n",
      "Number of 1 Higgs events: 0\n",
      "Number of 2 Higgs events: 0\n",
      "Number of 3 Higgs events: 8616\n",
      "\\item Total sample size: 11,521\n",
      "\\item 1h sample size: 0\n",
      "\\item 2h sample size: 0\n",
      "\\item 3h sample size: 8,616\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'total': 11521, '0h': 2905, '1h': 0, '2h': 0, '3h': 8616}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = '../SPANet2/data/triHiggs/triHiggs_0b_3h_test.h5'\n",
    "print_triHiggs_h5_info(file_path)\n",
    "\n",
    "output_file = '../SPANet2/data/triHiggs/triHiggs_6b_3h_test.h5'\n",
    "six_b_file = select_6b_event(file_path, output_file)\n",
    "print_triHiggs_h5_info(six_b_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../SPANet2/data/triHiggs/triHiggs_0b_3h_test.h5\n",
      "Dataset size: 200000\n",
      "Number of 0 Higgs events: 100000\n",
      "Number of 1 Higgs events: 0\n",
      "Number of 2 Higgs events: 0\n",
      "Number of 3 Higgs events: 100000\n",
      "\\item Total sample size: 200,000\n",
      "\\item 1h sample size: 0\n",
      "\\item 2h sample size: 0\n",
      "\\item 3h sample size: 100,000\n",
      "Number of 6 b events: 11521\n",
      "../SPANet2/data/triHiggs/triHiggs_6b_3h_test.h5\n",
      "Dataset size: 11521\n",
      "Number of 0 Higgs events: 2905\n",
      "Number of 1 Higgs events: 0\n",
      "Number of 2 Higgs events: 0\n",
      "Number of 3 Higgs events: 8616\n",
      "\\item Total sample size: 11,521\n",
      "\\item 1h sample size: 0\n",
      "\\item 2h sample size: 0\n",
      "\\item 3h sample size: 8,616\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'total': 11521, '0h': 2905, '1h': 0, '2h': 0, '3h': 8616}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "file_path = '../SPANet2/data/triHiggs/triHiggs_0b_3h_test.h5'\n",
    "print_triHiggs_h5_info(file_path)\n",
    "\n",
    "output_file = '../SPANet2/data/triHiggs/triHiggs_6b_3h_test.h5'\n",
    "six_b_file = select_6b_event(file_path, output_file)\n",
    "print_triHiggs_h5_info(six_b_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare training and testing datasets with at least 4 jet $ > 40 \\text{ GeV}$ and 4 $b$-tagged jet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of Sample/SPANet/gghhh_4b.h5: 3653696\n",
      "Size of Sample/SPANet/gghhh_4b_split1.h5: 1000000\n",
      "Size of Sample/SPANet/gghhh_4b_split2.h5: 2653696\n",
      "Size of Sample/SPANet/gghhh_4b_split2.h5: 2653696\n",
      "Size of Sample/SPANet/gghhh_4b_split2_split1.h5: 500000\n",
      "Size of Sample/SPANet/gghhh_4b_split2_split2.h5: 2153696\n"
     ]
    }
   ],
   "source": [
    "file_path = 'Sample/SPANet/gghhh_4b.h5'\n",
    "size = 1000000\n",
    "utils.split_h5_size(file_path, size)\n",
    "\n",
    "root, ext = os.path.splitext(file_path)\n",
    "split_file1 = root + '_split1' + ext\n",
    "split_file2 = root + '_split2' + ext\n",
    "\n",
    "os.rename(split_file1, './Sample/SPANet/gghhh_4b_PT40.h5')\n",
    "\n",
    "size = 500000\n",
    "utils.split_h5_size(split_file2, size)\n",
    "\n",
    "root, ext = os.path.splitext(split_file2)\n",
    "split_file1 = root + '_split1' + ext\n",
    "split_file2 = root + '_split2' + ext\n",
    "\n",
    "os.rename(split_file1, './Sample/SPANet/gghhh_4b_PT40_DNN.h5')\n",
    "os.remove(split_file2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of ./Sample/SPANet/gghhh_4b_PT40.h5: 1000000\n",
      "Size of ./Sample/SPANet/gghhh_4b_PT40_split1.h5: 900000\n",
      "Size of ./Sample/SPANet/gghhh_4b_PT40_split2.h5: 100000\n"
     ]
    }
   ],
   "source": [
    "file_path = './Sample/SPANet/gghhh_4b_PT40.h5'\n",
    "r = 0.9\n",
    "utils.split_h5_file(file_path, r)\n",
    "\n",
    "root, ext = os.path.splitext(file_path)\n",
    "split_file1 = root + '_split1' + ext\n",
    "split_file2 = root + '_split2' + ext\n",
    "\n",
    "os.rename(split_file1, './Sample/SPANet/gghhh_4b_PT40_train.h5')\n",
    "os.rename(split_file2, './Sample/SPANet/gghhh_4b_PT40_test.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../SPANet2/data/triHiggs/gghhh_4b_PT40_train.h5\n",
      "Dataset size: 900000\n",
      "Number of 0 Higgs events: 54693\n",
      "Number of 1 Higgs events: 246462\n",
      "Number of 2 Higgs events: 318057\n",
      "Number of 3 Higgs events: 280788\n",
      "\\item Total sample size: 900,000\n",
      "\\item 1h sample size: 246,462\n",
      "\\item 2h sample size: 318,057\n",
      "\\item 3h sample size: 280,788\n",
      "Number of 3 Higgs events: 280788\n",
      "../SPANet2/data/triHiggs/gghhh_4b_PT40_3h_train.h5\n",
      "Dataset size: 280788\n",
      "Number of 0 Higgs events: 0\n",
      "Number of 1 Higgs events: 0\n",
      "Number of 2 Higgs events: 0\n",
      "Number of 3 Higgs events: 280788\n",
      "\\item Total sample size: 280,788\n",
      "\\item 1h sample size: 0\n",
      "\\item 2h sample size: 0\n",
      "\\item 3h sample size: 280,788\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'total': 280788, '0h': 0, '1h': 0, '2h': 0, '3h': 280788}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = '../SPANet2/data/triHiggs/gghhh_4b_PT40_train.h5'\n",
    "print_triHiggs_h5_info(file_path)\n",
    "\n",
    "output_file = '../SPANet2/data/triHiggs/gghhh_4b_PT40_3h_train.h5'\n",
    "triHiggs_file = select_3h_event(file_path, output_file)\n",
    "print_triHiggs_h5_info(triHiggs_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../SPANet2/data/triHiggs/gghhh_4b_PT40_test.h5\n",
      "Dataset size: 100000\n",
      "Number of 0 Higgs events: 6208\n",
      "Number of 1 Higgs events: 27243\n",
      "Number of 2 Higgs events: 35050\n",
      "Number of 3 Higgs events: 31499\n",
      "\\item Total sample size: 100,000\n",
      "\\item 1h sample size: 27,243\n",
      "\\item 2h sample size: 35,050\n",
      "\\item 3h sample size: 31,499\n",
      "Number of 3 Higgs events: 31499\n",
      "../SPANet2/data/triHiggs/gghhh_4b_PT40_3h_test.h5\n",
      "Dataset size: 31499\n",
      "Number of 0 Higgs events: 0\n",
      "Number of 1 Higgs events: 0\n",
      "Number of 2 Higgs events: 0\n",
      "Number of 3 Higgs events: 31499\n",
      "\\item Total sample size: 31,499\n",
      "\\item 1h sample size: 0\n",
      "\\item 2h sample size: 0\n",
      "\\item 3h sample size: 31,499\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'total': 31499, '0h': 0, '1h': 0, '2h': 0, '3h': 31499}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = '../SPANet2/data/triHiggs/gghhh_4b_PT40_test.h5'\n",
    "print_triHiggs_h5_info(file_path)\n",
    "\n",
    "output_file = '../SPANet2/data/triHiggs/gghhh_4b_PT40_3h_test.h5'\n",
    "triHiggs_file = select_3h_event(file_path, output_file)\n",
    "print_triHiggs_h5_info(triHiggs_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../SPANet2/data/triHiggs/triHiggs_4b_PT40_3h_train.h5\n",
      "Dataset size: 280788\n",
      "Number of 0 Higgs events: 0\n",
      "Number of 1 Higgs events: 0\n",
      "Number of 2 Higgs events: 0\n",
      "Number of 3 Higgs events: 280788\n",
      "\\item Total sample size: 280,788\n",
      "\\item 1h sample size: 0\n",
      "\\item 2h sample size: 0\n",
      "\\item 3h sample size: 280,788\n",
      "Number of 6 b events: 76506\n",
      "../SPANet2/data/triHiggs/triHiggs_6b_PT40_3h_train.h5\n",
      "Dataset size: 76506\n",
      "Number of 0 Higgs events: 0\n",
      "Number of 1 Higgs events: 0\n",
      "Number of 2 Higgs events: 0\n",
      "Number of 3 Higgs events: 76506\n",
      "\\item Total sample size: 76,506\n",
      "\\item 1h sample size: 0\n",
      "\\item 2h sample size: 0\n",
      "\\item 3h sample size: 76,506\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'total': 76506, '0h': 0, '1h': 0, '2h': 0, '3h': 76506}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = '../SPANet2/data/triHiggs/triHiggs_4b_PT40_3h_train.h5'\n",
    "print_triHiggs_h5_info(file_path)\n",
    "\n",
    "output_file = '../SPANet2/data/triHiggs/triHiggs_6b_PT40_3h_train.h5'\n",
    "six_b_file = select_6b_event(file_path, output_file)\n",
    "print_triHiggs_h5_info(six_b_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./Sample/SPANet/gghhh_4b_PT40_new.h5\n",
      "Dataset size: 32337\n",
      "Number of 0 Higgs events: 2111\n",
      "Number of 1 Higgs events: 8941\n",
      "Number of 2 Higgs events: 11341\n",
      "Number of 3 Higgs events: 9944\n",
      "\\item Total sample size: 32,337\n",
      "\\item 1h sample size: 8,941\n",
      "\\item 2h sample size: 11,341\n",
      "\\item 3h sample size: 9,944\n",
      "Number of 3 Higgs events: 9944\n",
      "./Sample/SPANet/gghhh_4b_PT40_3h_new.h5\n",
      "Dataset size: 9944\n",
      "Number of 0 Higgs events: 0\n",
      "Number of 1 Higgs events: 0\n",
      "Number of 2 Higgs events: 0\n",
      "Number of 3 Higgs events: 9944\n",
      "\\item Total sample size: 9,944\n",
      "\\item 1h sample size: 0\n",
      "\\item 2h sample size: 0\n",
      "\\item 3h sample size: 9,944\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'total': 9944, '0h': 0, '1h': 0, '2h': 0, '3h': 9944}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = './Sample/SPANet/gghhh_4b_PT40_new.h5'\n",
    "print_triHiggs_h5_info(file_path)\n",
    "\n",
    "output_file = './Sample/SPANet/gghhh_4b_PT40_3h_new.h5'\n",
    "triHiggs_file = select_3h_event(file_path, output_file)\n",
    "print_triHiggs_h5_info(triHiggs_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample/SPANet/gghhh_4b.h5\n",
      "Dataset size: 3653696\n",
      "Number of 0 Higgs events: 223197\n",
      "Number of 1 Higgs events: 998906\n",
      "Number of 2 Higgs events: 1290603\n",
      "Number of 3 Higgs events: 1140990\n",
      "\\item Total sample size: 3,653,696\n",
      "\\item 1h sample size: 998,906\n",
      "\\item 2h sample size: 1,290,603\n",
      "\\item 3h sample size: 1,140,990\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'total': 3653696, '0h': 223197, '1h': 998906, '2h': 1290603, '3h': 1140990}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = 'Sample/SPANet/gghhh_4b.h5'\n",
    "print_triHiggs_h5_info(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of Sample/SPANet/gghhh_4b.h5: 3653696\n",
      "Size of Sample/SPANet/gghhh_4b_split1.h5: 500000\n",
      "Size of Sample/SPANet/gghhh_4b_split2.h5: 3153696\n"
     ]
    }
   ],
   "source": [
    "file_path = 'Sample/SPANet/gghhh_4b.h5'\n",
    "size = 500000\n",
    "utils.split_h5_size(file_path, size)\n",
    "\n",
    "root, ext = os.path.splitext(file_path)\n",
    "split_file1 = root + '_split1' + ext\n",
    "split_file2 = root + '_split2' + ext\n",
    "\n",
    "os.rename(split_file1, './Sample/SPANet/gghhh_4b_PT40.h5')\n",
    "os.remove(split_file2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of Sample/SPANet/gghhh_4b_PT40.h5: 500000\n",
      "Size of Sample/SPANet/gghhh_4b_PT40_split1.h5: 450000\n",
      "Size of Sample/SPANet/gghhh_4b_PT40_split2.h5: 50000\n"
     ]
    }
   ],
   "source": [
    "file_path = 'Sample/SPANet/gghhh_4b_PT40.h5'\n",
    "r = 0.9\n",
    "utils.split_h5_file(file_path, r)\n",
    "\n",
    "root, ext = os.path.splitext(file_path)\n",
    "split_file1 = root + '_split1' + ext\n",
    "split_file2 = root + '_split2' + ext\n",
    "\n",
    "os.rename(split_file1, './Sample/SPANet/gghhh_4b_PT40_train.h5')\n",
    "os.rename(split_file2, './Sample/SPANet/gghhh_4b_PT40_test.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of ./Sample/SPANet/pp6b_4b.h5: 790372\n",
      "Size of ./Sample/SPANet/pp6b_4b_split1.h5: 500000\n",
      "Size of ./Sample/SPANet/pp6b_4b_split2.h5: 290372\n"
     ]
    }
   ],
   "source": [
    "file_path = './Sample/SPANet/pp6b_4b.h5'\n",
    "size = 500000\n",
    "utils.split_h5_size(file_path, size)\n",
    "\n",
    "root, ext = os.path.splitext(file_path)\n",
    "split_file1 = root + '_split1' + ext\n",
    "split_file2 = root + '_split2' + ext\n",
    "\n",
    "os.rename(split_file1, './Sample/SPANet/pp6b_4b_PT40.h5')\n",
    "os.remove(split_file2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of ./Sample/SPANet/pp6b_4b_PT40.h5: 500000\n",
      "Size of ./Sample/SPANet/pp6b_4b_PT40_split1.h5: 450000\n",
      "Size of ./Sample/SPANet/pp6b_4b_PT40_split2.h5: 50000\n"
     ]
    }
   ],
   "source": [
    "file_path = './Sample/SPANet/pp6b_4b_PT40.h5'\n",
    "r = 0.9\n",
    "utils.split_h5_file(file_path, r)\n",
    "\n",
    "root, ext = os.path.splitext(file_path)\n",
    "split_file1 = root + '_split1' + ext\n",
    "split_file2 = root + '_split2' + ext\n",
    "\n",
    "os.rename(split_file1, './Sample/SPANet/pp6b_4b_PT40_train.h5')\n",
    "os.rename(split_file2, './Sample/SPANet/pp6b_4b_PT40_test.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'./Sample/SPANet/gghhh_4b_PT40_train.h5' and ('./Sample/SPANet/pp6b_4b_PT40_train.h5',) are same structure, can be merged.\n",
      "./Sample/SPANet/gghhh_4b_PT40_train_merged.h5 not exist. Copy ./Sample/SPANet/gghhh_4b_PT40_train.h5 to ./Sample/SPANet/gghhh_4b_PT40_train_merged.h5\n",
      "Size of ./Sample/SPANet/gghhh_4b_PT40_train.h5: 450000\n",
      "Size of ./Sample/SPANet/pp6b_4b_PT40_train.h5: 450000\n",
      "Size of ./Sample/SPANet/gghhh_4b_PT40_train_merged.h5: 900000\n",
      "'./Sample/SPANet/gghhh_4b_PT40_test.h5' and ('./Sample/SPANet/pp6b_4b_PT40_test.h5',) are same structure, can be merged.\n",
      "./Sample/SPANet/gghhh_4b_PT40_test_merged.h5 not exist. Copy ./Sample/SPANet/gghhh_4b_PT40_test.h5 to ./Sample/SPANet/gghhh_4b_PT40_test_merged.h5\n",
      "Size of ./Sample/SPANet/gghhh_4b_PT40_test.h5: 50000\n",
      "Size of ./Sample/SPANet/pp6b_4b_PT40_test.h5: 50000\n",
      "Size of ./Sample/SPANet/gghhh_4b_PT40_test_merged.h5: 100000\n"
     ]
    }
   ],
   "source": [
    "files = ['./Sample/SPANet/gghhh_4b_PT40_train.h5', \n",
    "         './Sample/SPANet/pp6b_4b_PT40_train.h5']\n",
    "\n",
    "merged_h5 = utils.merge_h5_file(*files)\n",
    "\n",
    "new_file = 'Sample/SPANet/triHiggs_4b_PT40_train.h5'\n",
    "\n",
    "os.rename(merged_h5, new_file)\n",
    "\n",
    "files = ['./Sample/SPANet/gghhh_4b_PT40_test.h5', \n",
    "         './Sample/SPANet/pp6b_4b_PT40_test.h5']\n",
    "\n",
    "merged_h5 = utils.merge_h5_file(*files)\n",
    "\n",
    "new_file = 'Sample/SPANet/triHiggs_4b_PT40_test.h5'\n",
    "\n",
    "os.rename(merged_h5, new_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 900000\n",
      "Dataset size: 100000\n"
     ]
    }
   ],
   "source": [
    "utils.shuffle_h5('Sample/SPANet/triHiggs_4b_PT40_train.h5')\n",
    "utils.shuffle_h5('Sample/SPANet/triHiggs_4b_PT40_test.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare training and testing datasets in the $6b$ region "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of Sample/SPANet/gghhh_6b.h5: 486694\n",
      "Size of Sample/SPANet/gghhh_6b_split1.h5: 400000\n",
      "Size of Sample/SPANet/gghhh_6b_split2.h5: 86694\n"
     ]
    }
   ],
   "source": [
    "file_path = 'Sample/SPANet/gghhh_6b.h5'\n",
    "size = 400000\n",
    "utils.split_h5_size(file_path, size)\n",
    "\n",
    "root, ext = os.path.splitext(file_path)\n",
    "split_file1 = root + '_split1' + ext\n",
    "split_file2 = root + '_split2' + ext\n",
    "\n",
    "os.rename(split_file1, './Sample/SPANet/gghhh_6b_PT40.h5')\n",
    "os.rename(split_file2, './Sample/SPANet/gghhh_6b_PT40_DNN.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of ./Sample/SPANet/gghhh_6b_PT40.h5: 400000\n",
      "Size of ./Sample/SPANet/gghhh_6b_PT40_split1.h5: 360000\n",
      "Size of ./Sample/SPANet/gghhh_6b_PT40_split2.h5: 40000\n"
     ]
    }
   ],
   "source": [
    "file_path = './Sample/SPANet/gghhh_6b_PT40.h5'\n",
    "r = 0.9\n",
    "utils.split_h5_file(file_path, r)\n",
    "\n",
    "root, ext = os.path.splitext(file_path)\n",
    "split_file1 = root + '_split1' + ext\n",
    "split_file2 = root + '_split2' + ext\n",
    "\n",
    "os.rename(split_file1, './Sample/SPANet/gghhh_6b_PT40_train.h5')\n",
    "os.rename(split_file2, './Sample/SPANet/gghhh_6b_PT40_test.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./Sample/SPANet/gghhh_6b_PT40_train.h5\n",
      "Dataset size: 360000\n",
      "Number of 0 Higgs events: 4607\n",
      "Number of 1 Higgs events: 38595\n",
      "Number of 2 Higgs events: 73036\n",
      "Number of 3 Higgs events: 243762\n",
      "\\item Total sample size: 360,000\n",
      "\\item 1h sample size: 38,595\n",
      "\\item 2h sample size: 73,036\n",
      "\\item 3h sample size: 243,762\n",
      "Number of 3 Higgs events: 243762\n",
      "./Sample/SPANet/gghhh_6b_PT40_3h_train.h5\n",
      "Dataset size: 243762\n",
      "Number of 0 Higgs events: 0\n",
      "Number of 1 Higgs events: 0\n",
      "Number of 2 Higgs events: 0\n",
      "Number of 3 Higgs events: 243762\n",
      "\\item Total sample size: 243,762\n",
      "\\item 1h sample size: 0\n",
      "\\item 2h sample size: 0\n",
      "\\item 3h sample size: 243,762\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'total': 243762, '0h': 0, '1h': 0, '2h': 0, '3h': 243762}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = './Sample/SPANet/gghhh_6b_PT40_train.h5'\n",
    "print_triHiggs_h5_info(file_path)\n",
    "\n",
    "output_file = './Sample/SPANet/gghhh_6b_PT40_3h_train.h5'\n",
    "triHiggs_file = select_3h_event(file_path, output_file)\n",
    "print_triHiggs_h5_info(triHiggs_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./Sample/SPANet/gghhh_6b_PT40_test.h5\n",
      "Dataset size: 40000\n",
      "Number of 0 Higgs events: 483\n",
      "Number of 1 Higgs events: 4360\n",
      "Number of 2 Higgs events: 8070\n",
      "Number of 3 Higgs events: 27087\n",
      "\\item Total sample size: 40,000\n",
      "\\item 1h sample size: 4,360\n",
      "\\item 2h sample size: 8,070\n",
      "\\item 3h sample size: 27,087\n",
      "Number of 3 Higgs events: 27087\n",
      "./Sample/SPANet/gghhh_6b_PT40_3h_test.h5\n",
      "Dataset size: 27087\n",
      "Number of 0 Higgs events: 0\n",
      "Number of 1 Higgs events: 0\n",
      "Number of 2 Higgs events: 0\n",
      "Number of 3 Higgs events: 27087\n",
      "\\item Total sample size: 27,087\n",
      "\\item 1h sample size: 0\n",
      "\\item 2h sample size: 0\n",
      "\\item 3h sample size: 27,087\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'total': 27087, '0h': 0, '1h': 0, '2h': 0, '3h': 27087}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = './Sample/SPANet/gghhh_6b_PT40_test.h5'\n",
    "print_triHiggs_h5_info(file_path)\n",
    "\n",
    "output_file = './Sample/SPANet/gghhh_6b_PT40_3h_test.h5'\n",
    "triHiggs_file = select_3h_event(file_path, output_file)\n",
    "print_triHiggs_h5_info(triHiggs_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
